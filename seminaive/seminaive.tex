\documentclass{article}
\usepackage[a4paper,margin=0.8in]{geometry}

\usepackage{datafun}

%% Allows using >{blah} and <{blah} in array formats.
\usepackage{array}

%% for \midrule
\usepackage{booktabs}

\newcommand{\dummy}{\ms{dummy}}

\begin{document}

\section{Poset terminology}

\begin{definition}[Chain]
  In a poset $A$, a \emph{chain} is a monotone map $f : \N \to A$, which we
  interpret as an infinite nondecreasing sequence of $A$s, $f(0) \le f(1) \le
  f(2) \le ...$.
\end{definition}

\begin{definition}[Strict chain]
  A chain $f : \N \to A$ is \emph{strict} if $i < j \implies f(i) < f(j)$; in
  other words, an infinite strictly increasing sequence of $A$s, $f(0) < f(1) <
  f(2) < ...$.
\end{definition}

\begin{definition}[Stops at]
  A chain $a_0 \le a_1 \le a_2 \le ...$ \emph{stops at $i$} iff $a_i$ is the
  supremum of all $a_j$. Equivalent formulations:
  \[\begin{array}{ccccc}
    a_i = \sup_j a_j
    &\Leftrightarrow& \forall(j \ge i)\ a_j \le a_i
    &\Leftrightarrow& \forall(j \ge i)\ a_i = a_j\\
  \end{array}\]
\end{definition}

\begin{definition}[Stops]
  A chain $a$ \emph{stops} iff it contains its own supremum (iff $\exists
  i\binder a~\text{stops at}~i$).
\end{definition}

\begin{observation} Strict chains don't stop. \end{observation}

\begin{definition}
  For a chain $f$, let the sequence $f^s$ (``the strictification of $f$'') be
  $f$ with all repeated elements stripped out. If $f^s$ is infinite, it is by
  construction a strict chain.
\end{definition}

%% \begin{observation}
%%   If $f$ is a strict chain, $f^s = f$, since strict chains have no repeated
%%   elements.
%% \end{observation}

\begin{lemma}
  Given a chain $a$, $a^s$ is finite iff $a$ stops (and $a^s$ is a strict chain
  iff $a$ does not stop).
\end{lemma}
\begin{proof}
  Note that the ranges of $a$ and $a^s$ are identical by construction.

  First, suppose $a^s$ is finite. Note that the last element of $a^s$ is its
  largest, and therefore the supremum of both sequences, since they have the
  same range. Therefore $a$ contains its own supremum, and stops.

  Second, suppose $a$ stops. Thus it contains the supremum of both sequences.
  Let $i$ be the index such that $a^s_i$ is this supremum. There can be no
  elements in $a^s$ after $a^s_i$. Thus $a^s$ is finite.
\end{proof}

\begin{definition}[ACC]
  A poset satisfies the \emph{ascending chain condition (ACC)} iff all chains in
  it stop, or equivalently, if it has no strict chains.
\end{definition}

``Every chain stops'' implies no strict chains exist, since every strict chain
is a chain and strict chains do not stop. Likewise, ``no strict chains exist''
implies every chain stops, since for every non-stopping chain $f$ there is a
strict chain $f^s$.

%% \begin{theorem}[ACC $\Leftrightarrow$ no strict chains]
%%   A poset $A$ satisfies ACC iff there are no strict chains on $A$.
%% \end{theorem}
%% \begin{proof}
%%   First, we show ACC implies no strict chains. Assume $A$ satisfies ACC.
%%   Consider some strict chain $f : \N \to A$. Any strict chain is a chain.
%%   Therefore by ACC $\exists i\ \forall(j \ge i)\ f(j) \le f(i)$. Letting $j = i
%%   + 1$, we have $f(i) < f(i + 1)$ by $f$'s strictness, and $f(i) \ge f(i+1)$ by
%%   ACC. Contradiction!

%%   Second, we show no strict chains implies ACC. Assume $A$ has no strict chains.
%%   Consider some (weak) chain $f : \N \to A$. Now, let the sequence $f^s$ be $f$
%%   with repeated elements stripped out, so that $f^s$ is strictly increasing, but
%%   might no longer be an infinite sequence. Since $A$ has no strict chains, we
%%   know $f^s$ is finite. Consider the index $i$ in $f$ of the first occurrence of
%%   the last (and thus greatest) element of $f^s$. By construction we have
%%   $\forall (j \ge i)\ f(j) \le f(i)$. Thus $A$ satisfies ACC.
%% \end{proof}

\begin{definition}[Downset on an element]
  The \emph{downset on $x$} in a poset $A$, written $\downintro{x : A}$ or just
  $\downintro{x}$, is the freely generated downward-closed subset of $A$
  containing $x$, namely $\setfor{y \in A}{y \le x}$.
\end{definition}

\begin{definition}[Downset]
  A \emph{downset} on a poset $A$ is a finitely-generated downward-closed subset
  of $A$; that is to say, for some \emph{finite} subset $G \finsubseteq A$, it
  is $\bigcup_{x \in G} \downintro{x}$, or equivalently $\setfor{y \in
    A}{\exists(x \in G)\ y \le x}$.
\end{definition}

Note that this definition of \emph{downset} is in fact what others might call a
\emph{finitely generated downset}. I prefer the term \emph{downward-closed set}
for the more general concept.

We will often regard a downset $D$ of $A$ as a poset, with the same ordering
relation as $A$, restricted to elements of $D$ (the ``induced ordering'').

\begin{definition}[Downset ACC]
  A poset $A$ is \emph{downset-ACC} iff every downset $D$ of $A$ satisfies
  ACC.
\end{definition}

\begin{lemma}[The union of ACC sets is ACC]\label{lemma:acc-union}
  Given a poset $\tuple{A,\le}$ and two subsets $B,C \subseteq A$, if
  $\tuple{B,\le}$ and $\tuple{C,\le}$ each satisfy ACC, then so does $\tuple{B
    \cup C, \le}$.
\end{lemma}
\begin{proof}
  Assume $B$ and $C$ satisfy ACC.
  %%
  It suffices to show that there are no strict chains in $B \cup C$.
  So consider some strict chain $f : \N \to B \cup C$.
  %%

  We can split $f(0) < f(1) < f(2) < ...$ into two strictly increasing sequences
  $b_0 < b_1 < b_2 < ...$ and $c_0 < c_1 < c_2 < ...$ by including in $b_i$ all
  and only those $f(j) \in B$ and likewise in $c_i$ all and only those $f(j) \in
  C$. Since $f$ is infinite, at least one of these sequence is infinite; WLOG,
  assume $b$ is. Thus $b$ is a strict chain in $B$! But by ACC there are no
  strict chains in $B$. Contradiction.
\end{proof}

\begin{theorem}[Elementwise ACC implies Downset ACC]
  A poset $A$ is downset-ACC if, for any $x : A$, $\downintro{x}$ satisfies ACC.
\end{theorem}
\begin{proof}
  The empty set clearly satisfies ACC. Given two subposets $D,E \subseteq A$
  which both satisfy ACC, their union $D \cup E$ also satisfies ACC by Lemma
  \ref{lemma:acc-union}. Every downset is the finite union of zero or more
  singly-generated downsets of the form $\downintro{x}$. So by induction, if
  every singly-generated downset $\downintro{x}$ satisfies ACC, so do all
  downsets.
\end{proof}



\section{Core Datafun}

\todo{We should carefully distinguish which properties are necessary to safely
  extend core Datafun --- and therefore, which proofs are ``open''. For example,
  all that should be necessary to add a type to Datafun and declare it decidable
  is that it should actually \emph{be} decidable. However, for \emph{decidable
    semilattice types}, we require that Lemma \ref{lemma:dl-boring} holds in
  order to extend the language with them.

  This means that when proving something about decidable types, we cannot do it
  by induction (or we violate extensibility), only by invoking the fact that
  they are decidable. But when proving something about decidable semilattice
  types, we can use Lemma \ref{lemma:dl-boring}. The proof of Lemma
  \ref{lemma:dl-boring} gets to use induction, but the hypothesis can't be
  strengthened (or we'd violate extensibility).}

\subsection{Syntax}

\[
\begin{array}{rccl}
  \textsf{types} & A,B,C
  &\bnfeq& A \to B \pipe A \x B \pipe A + B
  \pipe \Disc{A} \pipe \Down{\eq{A}} \pipe \tbool
  \vspace{1em}\\

  %% types where the poset relationship is decidable
  \textsf{decidable types} & \eq{A}
  &\bnfeq& \eq{A} \x \eq{B} \pipe \eq{A} + \eq{B}
  \pipe \Disc{\eq{A}} \pipe {\color{red} \Down{\eq{A}}} \pipe \tbool
  \vspace{1em}\\

  %% finite types
  \textsf{finite types} & \fin{A}
  &\bnfeq& \fin{A} \x \fin{B} \pipe \fin{A} + \fin{B}
  \pipe \Disc{\fin{A}} \pipe \Down{\fin{A}} \pipe \tbool
  \vspace{1em}\\

  %% acc types
  \textsf{acc types} & \acc{A}
  &\bnfeq& \acc{A} \x \acc{B} \pipe \acc{A} + \acc{B}
  \pipe \Disc{A} \pipe \Down{\fin{A}} \pipe \tbool
  \vspace{1em}\\

  %% downset-acc types
  \textsf{downset-acc types} & \eltacc{A}
  &\bnfeq& \eltacc{A} \x \eltacc{B} \pipe \eltacc{A} + \eltacc{B}
  \pipe \Disc{A}
  \pipe {\color{Cerulean} \Down{\fin{A}}} \pipe \Down{\Disc{A}}
  \pipe \tbool
  \vspace{1em}\\

  %% semilattice types
  \textsf{semilattice types} & \lat{A}
  &\bnfeq& A \to \lat{B} \pipe \lat{A} \x \lat{B} \pipe \Down{A} \pipe \tbool
  \vspace{1em}\\

  %% decidable semilattice types
  \textsf{decidable semilattice types} & \eqlat{A}
  &=& \eq{A} \cap \lat{A}
  \vspace{1em}\\

  %% fixpoint types
  \textsf{fixed-point types} & \fixtype{A}
  &=& \eq{A} \cap \lat{A} \cap \acc{A}
  \vspace{1em}\\

  \textsf{bounded fixed-point types} & \fixintype{A}
  &=& \eq{A} \cap \lat{A} \cap \eltacc{A}
  \vspace{1em}\\

  %% expressions
  \textsf{expressions} & e,f,g
  &\bnfeq& x \pipe \d{x} \pipe \fn\bind{x} e \pipe e\; e
  \pipe \pair{e}{e} \pipe \pi_i\; e
  \pipe \inj{i}{e} \pipe \case{e}{x}{e_1}{x}{e_2} \\
  &&\pipe& \disc{e} \pipe \letdisc{\d{x}}{e}{e} \pipe \splitsum{e}\\
  &&\pipe& \unit \pipe e \vee e \pipe \downintro{e} \pipe \downelim{x}{e}{e}\\
  &&\pipe& \etrue \pipe \efalse \pipe \when{e}{e} \pipe \ifthen{e}{e}{e}\\
  &&\pipe& \fix{x}{e} \pipe \fixin{x}{e}{e}
\end{array}
\]

\todo{Note: I try to use bold $\d{x}$ for discrete variables and ordinary script
  $x$ for monotone variables, but sometimes I screw up. Also, this is the
  opposite of the convention in the original Datafun paper.}

The ``typeclass'' rules (for decidable, finite, acc, downset-acc, semilattice,
etc.\! types) are \emph{conservative approximations} of semantic conditions.

``Decidable types'' are those whose partial ordering relation is practically
decidable; that is, given $x, y : \eq{A}$, there is a reasonable algorithm that
determines whether $x \le y$. By antisymmetry, this also makes equality $x = y$
testable at these types.

Theoretically, a function type $\under{fin}{A} \to \eq{B}$ whose domain is
finite and codomain is decidable is also decidable (it is effectively a finite
product of $\eq{B}$s). We have omitted this, as it complicates our
implementation for little practical benefit. We have similarly omitted the cases
in which function types are finite ($\fin{A} \to \fin{B}$), ACC ($\fin{A} \to
\acc{B}$), and downset-ACC ($\fin{A} \to \eltacc{B}$).

I've highlighted the decidable type ${\color{red} \Down{\eq{A}}}$ because
comparing down-sets \emph{efficiently} in general is nontrivial (impossible?).
If finite sets $\{A\}$ are implemented as $\Down{\Disc{A}}$, this may have
performance implications. A less general approach would be to consider only
$\Down{\Disc{\eq{A}}}$ to be decidable.

I've highlighted the downset-acc type ${\color{Cerulean} \Down{\fin{A}}}$
because, while correct, it seems insufficiently general. In particular it does
not cover the extremely useful special case that $\Down{\Disc{A}}$ (finite sets
of $A$s) is always downset-acc. However, $\Down{A}$ is not always downset-ACC;
consider $\Down{(\N \mathop{\under{<}{{+}}} 1)}$. \todo{I suspect the correct
  rule is that $\Down{\eltacc{A}}$ is always downset-acc, but this needs proof.
  This would generalize $\Down{\Disc{A}}$ as long as we keep the rules that
  $\Disc{A}$ is always ACC and downset-ACC.}


\subsection{Typing rules}

The typing judgment \[\J{\GP}{\GG}{e}{A}\] says that $e$ has type $A$ using
variables with types given by $\GP \cup \GG$, and moreover uses the variables in
$\GG$ in a monotone fashion.

Where possible without ambiguity, I omit the contexts $\GP;\GG$ from typing
rules.

\begin{mathpar}
  \infer{\J{\GP}{\GG}{x}{A}}{x \of A \in \GP \cup \GG}

  \infer{\fn\bind{x} e : A \to B}{\J{\GP}{\GG,x \of A}{e}{B}}

  \infer{e \; f : B}{e : A \to B & f : A}
  \\
  %% \infer{\pair{e}{f} : A \x B}{e : A & f : B}
  \infer{\pair{e_1}{e_2} : A_1 \x A_2}{e_i : A_i}

  \infer{\pi_i\; e : A_i}{e : A_1 \x A_2}

  \infer{\inj{i}{e} : A_1 + A_2}{e : A_i}

  \infer{\case{e}{x}{f_1}{x}{f_2} : B}
        {e : A_1 + A_2 & \J{\GP}{\GG, x \of A_i}{f_i}{B}}
  \\
  \infer{\J{\GP}{\GG}{\disc{e}}{\Disc{A}}}{\J{\GP}{-}{e}{A}}

  \infer{\letdisc{\d{x}}{e}{f} : B}
        { e : \Disc{A}
        & \J{\GP,\d{x}\of A}{\GG}{f}{B} }

  \infer{\splitsum{e} : \Disc{A} + \Disc{B}}
        {e : \Disc{(A + B)}}
  \\
  \infer{\unit : \lat{A}}{}

  \infer{e_1 \vee e_2 : \lat{A}}{e_i : \lat{A}}

  \infer{\downintro{e} : \Down{A}}{e : A}

  \infer{\downelim{x}{e}{f} : \lat{B}}
        { e : \Down{A}
        & \J{\GP}{\GG,x \of A}{f}{\lat{B}}}
  \\
  \infer{\etrue : \tbool}{}

  \infer{\efalse : \tbool}{}

  \infer{\when{e}{f} : \lat{A}}{e : \tbool & f : \lat{A}}

  \infer{\ifthen{e}{f_1}{f_2} : A}{e : \Disc{\tbool} & f_i : A}
  \\
  \infer{\fix{x}{e} : \fixtype{A}}{
    \J{\GP}{\GG,x\of \fixtype{A}}{e}{\fixtype{A}}}

  \infer{\fixin{x}{e}{f} : \fixintype{A}}{
    e : \Down{\fixintype{A}} &
    \J{\GP}{\GG,x \of \fixintype{A}}{f}{\fixintype{A}}}
\end{mathpar}


\section{A Theory of Changes for Core Datafun}

\subsection{Change types}

For each type $A$ we define a change type $\GD A$.

\[\begin{array}{rcl>{\quad\quad}rcl}
  \GD(A \to B) &=& \Disc{A} \to \Delta A \to \Delta B\\
  \GD(A \x B) &=& \GD A \x \GD B\\
  \GD(A + B) &=& \GD A + \GD B\\
  \GD(\Disc{A}) &=& \Disc{\GD A}\\
  \GD(\Down{A}) &=& \Down{A}\\
  \GD \tbool &=& \tbool
\end{array}\]

We also define associated operators $\oplus : A \to \GD A \to A$, $\ominus : A
\to A \to \Delta A$ and $\mb{0} : A \to \Delta A$. Note, however, the
definitions of these operators \emph{are not well-typed Datafun terms}. \todo{I
  do not believe there exists a way to assign them tones that is compatible with
  Datafun's type system; every way I've tried fails. But I have not proved
  this.}

As for the semantic tonal behavior of these operators, I believe I know this
much:
\begin{itemize}
\item $x \oplus dx$ is monotone in $dx$.
\item $x \ominus y$ is monotone in $x$ and antitone in $y$.
\item $\mb{0}$ is discrete; at function type, it finds the derivative of its
  argument, and a function that is larger pointwise does not necessarily have a
  derivative that is larger pointwise.
\end{itemize}

But is $\oplus$ monotone in its first argument? I'm not sure. It seems wrong to
contemplate changing its first argument without also changing its second ---
really it should have a dependent type.

\begin{center}
\[
\scalebox{0.9}{\(
\arraycolsep=1.5em
\begin{array}{cccc}
  \textbf{Type}
  & {\textbf{Definition of}~\oplus}
  & {\textbf{Definition of}~\ominus}
  & {\textbf{Definition of}~\mb{0}}
  \\ \midrule
  A \to B
  & (f \oplus df)\; x = f\; x \oplus df\; x\; (\mb{0}\; x)
  & (f \ominus g)\; x \;dx = f\; (x \oplus dx) \ominus g \; x
  & \mb{0}\; f\; x\; dx = f\; (x \oplus dx) \ominus f\; x
  \\
  A \x B
  & \pair{x}{y} \oplus \pair{dx}{dy} = \pair{x \oplus dx}{y \oplus dy}
  & \pair{a}{x} \ominus \pair{b}{y} = \pair{a \ominus b}{x \ominus y}
  & \mb{0} \; \pair{x}{y} = \pair{\mb{0}\; x}{\mb{0}\; y}
  \\
  A + B
  & \inj{i}{x} \oplus \inj{i}{dx} = \inj{i}{(x \oplus dx)}
  & \inj{i}{x} \ominus \inj{i}{y} = \inj{i}{x \ominus y}
  & \mb{0}\; (\inj{i}{x}) = \inj{i}{(\mb{0}\;x)}
  \\
  \Disc{A}
  & \disc{x} \oplus \disc{dx} = \disc{x \oplus dx}
  & \disc{x} \ominus \disc{y} = \disc{x \ominus y}
  & \mb{0}\; \disc{x} = \disc{\mb{0}\; x}
  \\
  \Down{A}
  & x \oplus y = x \vee y
  & x \ominus y = x
  & \mb{0}\; x = \unit
  \\
  \tbool
  & x \oplus y = x \vee y
  & x \ominus y = x
  & \mb{0}\; x = \unit
\end{array}
\)}
\]
\end{center}

These should satisfy the following laws:
\begin{eqnarray}
  x \le y \quad\implies\quad
  y &=& x \oplus (y \ominus x)\\
  x &=& x \oplus \mb{0}\; x
\end{eqnarray}

\todo{TODO: Prove these laws hold.}

\todo{TODO: Note about ``erasure''/invalid changes. Moreover, at $\Disc{A}$
  type, only valid changes are zero changes.}

\todo{TODO: Note about efficiency of computing $\oplus$, $\ominus$, $\mb{0}$,
  and which ones we actually need to compute in the implementation. Define
  efficiently computable $(- \ominus \unit)$ operator for decidable types, and
  point out that $\mb{0}$ is efficiently computable for decidable types.}

%% Zero on decidable types.
%% Zero on decidable types:
%% \[\arraycolsep=1.5em
%% \begin{array}{c|c}
%%   \eq{A} \x \eq{B}
%%   & \mb{0}\; (x,y) = (\mb{0}\; x, \mb{0}\; y)
%%   \\
%%   \eq{A} + \eq{B}
%%   & \mb{0}\; (\inj{i}{x}) = \inj{i}(\mb{0}\; x)\\
%%   \Disc{\eq{A}}
%%   & \mb{0}\;(\disc{x}) = \disc{(\mb{0}\; x)}\\
%%   \Down{\eq{A}} & \mb{0}\;x = \unit\\
%%   \tbool & \mb{0}\; x = \unit
%% \end{array}
%% \]


%% Some lemmas.
\begin{lemma}[Changes on a semilattice form a semilattice]
  $\GD \lat{A}$ is a semilattice type.

  \todo{TODO: do we actually need/use this lemma?}
\end{lemma}
\begin{proof}
  By induction on the cases:
  \begin{eqnarray*}
    \GD(A \to \lat{B}) &=& \Disc{A} \to \GD A \to \GD \lat{B}\\
    \GD(\lat{A} \x \lat{B}) &=& \GD \lat{A} \x \GD \lat{B}\\
    \GD(\Down{A}) &=& \Down{A}\\
    \GD 2 &=& 2
  \end{eqnarray*}
\end{proof}

\begin{lemma}[Changes on decidable semilattices are boring]\label{lemma:dl-boring}
  For any decidable semilattice type $\eqlat{A}$, $\GD \eqlat{A} = \eqlat{A}$,
  and moreover the following laws hold:
  \begin{eqnarray*}
    x \oplus y &=& x \vee y\\
    x \ominus y &=& x\\
    \mb{0}\; x &=& \unit
  \end{eqnarray*}
\end{lemma}
\begin{proof}
  By induction on the cases:
  \[\begin{array}{rcl}
    \GD(\eqlat{A} \x \eqlat{B}) &=& \GD \eqlat{A} \x \GD \eqlat{B}\\
    \GD(\Down{\eq{A}}) &=& \Down{\eq{A}}\\
    \GD \tbool &=& \tbool
  \end{array}\]

  And, for the operations:
  \[\arraycolsep=0.75em
  \begin{array}{c|ccc}
    \eqlat{A} \x \eqlat{B}
    & (x,y) \oplus (dx,dy) = (x \oplus dx, y \oplus dy)
    & (a,x) \ominus (b,y) = (a \ominus b, x \ominus y)
    & \mb{0}\; (x,y) = (\mb{0}\; x, \mb{0}\; y)\\
    \Down{\eq{A}}
    & x \oplus y = x \vee y
    & x \ominus y = x
    & \mb{0}\;x = \unit\\
    \tbool
    & x \oplus y = x \vee y
    & x \ominus y = x
    & \mb{0}\;x = \unit\\
  \end{array}
  \]
\end{proof}


\subsection{Derivatives}

We wish to define an operator $\delta$ on typing derivations (or if possible, on
well-typed terms) such that the following holds:
\[\infer{\J{\GP,\GD\GP,\GG}{\GD\GG}{\delta e}{\Delta A}}
        {\J{\GP}{\GG}{e}{A}}
\]

As a matter of convention, prefixing a variable with $d$ refers to the
corresponding variable of its change type. That is, if $x \of A \in \GP \cup
\GG$, then $dx \of \GD A \in \GD\GP \cup \GD\GG$. We also make implicit use of
weakening and monotone-to-discrete weakening (that is, if
$\J{\GP}{\GG_1,\GG_2}{e}{A}$, then $\J{\GP,\GG_1}{\GG_2}{e}{A}$).

\todo{\indent Furthermore, if $e : A$ originally, then in the the $\delta$-context,
  $\disc{e} : \Disc{A}$ for free, since all the variables $e$ uses are now
  discrete. Can/do we take advantage of this?} {\color{ForestGreen} Yes we do!
  See the green $(\disc{e})$ in the case for \textsf{when-then} below.}

\[
\begin{array}{lcll}
  \delta x &=& dx\\
  \delta \d{x} &=& \d{dx}\\
  \delta(\fn\bind{x} e) &=&
  \fn\bind{y} \letdisc{\d{x}}{y} {\fn\bind{dx} \delta e}
  \qquad\text{(for fresh $y$)}\\
  \delta(e\;f) &=& \delta e \; f \; \delta f\\
  \delta \pair{e}{f} &=& \pair{\delta{e}}{\delta{f}}\\
  \delta(\pi_i\; e) &=& \pi_i\; \delta{e}\\
  \delta(\inj{i}{e}) &=& \inj{i}{\delta{e}}\\
  \delta(\case{e}{x}{f}{y}{g})
  %% &=& \case{\splitsum{\color{ForestGreen} \disc{e}}}
  %%       {\disc{\d{x}}}{\case{\delta e}{dx}{\delta f}{\_}{\todo{\ms{abort!}}}}
  %%       {\disc{\d{x}}}{\textit{(symmetric case)}}\\
  &=& \ms{case}(\splitsum{\color{ForestGreen}\disc{e}};\\
   && \phantom{\ms{case}\ }
      \bind{\disc{\d{x}}}
      \letv{dx}{\case{\delta e}{dx}{dx}{\_}{\dummy\;\d{x}}} \delta f;\\
   && \phantom{\ms{case}\ }
      \bind{\disc{\d{y}}}
      \letv{dy}{\case{\delta e}{\_}{\dummy\;\d{y}}{dy}{dy}} \delta g)\\
  \delta\disc{e} &=& \disc{\delta e}\\
  \delta(\letdisc{\d{x}}{e} f) &=&
  \letdisc{\d{x}}{e}
    \letdisc{\d{dx}}{\delta e} \delta f\\
  \delta(\splitsum{e}) &=&
  %% want type: Δ□A + Δ□B = □ΔA + □ΔB
  %% e : □(A + B)
  %% δe : □(ΔA + ΔB)
  %% splitsum δe : □ΔA + □ΔB
  \splitsum{\delta e}\\
  \delta \unit &=& \unit\\
  \delta(e \vee f) &=& \delta e \vee \delta f
  \qquad \text{(this is the critical over-approximation)}\\
  \delta(\downintro{e}) &=& \unit\\
  \delta(\downelim{\d{x}}{e}{f}) &=& \text{\todo{see below}}\\
  \delta(\etrue) &=& \efalse\\
  \delta(\efalse) &=& \efalse\\
  \delta(\when{e}{f})
  &=& \ifthen{\color{ForestGreen} \disc{e}}{\delta f}{
    \when{\delta e}{(f \oplus \delta f) \ominus \unit}}
  \qquad \text{\color{red} see below}\\
  \delta(\ifthen{e}{f}{g}) &=& \ifthen{e}{\delta f}{\delta g}\\
  \delta(\fix{x}{e}) &=&
  \letdisc{\d{x}}{\disc{\fix{x} e}}{\fix{dx} \delta e}\\
  \delta(\fixin{x}{e}{f}) &=& \text{\TODO}
\end{array}
\]

At equality types, $\delta(\downelim{x}{e}{f})$ has the following definition:

\[\begin{array}{rcl}
  \delta(\downelim{x}{e}{f})
  &=& \phantom{\vee~} (\downelim{x}{e}{\ms{let}~dx = \mb{0}\; x ~\ms{in}~ \delta f})
  \\ && \vee~ (\downelim{x}{\delta e}{\ms{let}~dx = \mb{0}\; x ~\ms{in}~
    (f \oplus \delta f) \ominus \unit})
\end{array}\]

\todo{TODO: Explain/show that $\oplus$, $(- \ominus \unit)$, and \mb{0} are
  definable, typeable, and efficiently computable at these types!}

Translation of $\downelim{x}{e}{f}$ at \emph{non-equality types}, however, is
type-directed:

\[\begin{array}{lcll}
  \delta(\downelim{x}{e}{f} : A \to \lat{B})
  &=& \fn\bind{y} \downelim{x}{e}{f\; y}\\
  \delta(\downelim{x}{e}{f} : \lat{A} \x \lat{B})
  &=& \pair{\delta(\downelim{x}{e}{\pi_1\; f})}
  {\delta(\downelim{x}{e}{\pi_2\; f})}
\end{array}\]

\emph{Hypothesis}: For $a : \lat{A}$ and $da : \GD\lat{A}$ a valid change to
$a$:
\begin{equation*}
  (a \oplus da) \ominus \unit = (a \ominus \unit)
  \vee da
\end{equation*}

\emph{Observation}: Consider $(\when{e}{f})$ for $f : A \to \lat{B}$. We can
rewrite this as $(\fn\bind{x} \when{e}{f\; x})$. This turns a \ms{when} at type
$A \to \lat{B}$ into one at type $\lat{B}$. By extending this we can rewrite
away all uses of \ms{when} at functional types, in the same manner as we can
rewrite away uses of $\bigvee$ at functional type.

\todo{\par TODO: Proofs which Neel \& I worked out last time.}


\subsubsection{Dummy values}

The derivative of $\ms{case}$ has branches we know semantically cannot occur;
but to appease the type system, we need to put an expression in those branches
of the appropriate type. Instead of introducing an \ms{abort} construct, which
would complicate our semantics, we generate an expression of the appropriate
type using a type-indexed dummy-value function $\dummy{} : A \to \Delta{A}$.

\[\begin{array}{lcl}
\dummy\; (x : \tbool) &=& \efalse\\
\dummy\; (x : \Down{A}) &=& \unit\\
\dummy\; \pair{x}{y} &=& \pair{\dummy\;x}{\dummy\;y}\\
\dummy\; (\inj{i}{x}) &=& \inj{i}{(\dummy\;x)}\\
\dummy\; \disc{\d{x}} &=& \disc{\dummy\; \d{x}}\\
\dummy\; (f : A \to B) &=& \fn x\,dx\binder\, \dummy\;(f\;x)
\end{array}\]

This is a hack to simplify our metatheory. A real implementation would not do
this.

\todo{NB. To add a type to Datafun, we must extend \dummy{} appropriately.}


\subsubsection{Justifying derivatives of fixed points}

Our rule for the derivative of a fixed point is:
\begin{eqnarray*}
  \delta(\fix{x} e)
  &=& \letdisc{\d{x}}{\disc{\fix{x} e}}{\fix{dx} \delta e}\\
  &=& \fix{dx}
      (\fn \d{x}\, dx\binder \delta e)
      \; \disc{\fix{x} e}
      \; dx\\
  &=& \fix{dx} \delta(\fn\bind{x} e)
      \; \disc{\fix{x} e}
      \; dx
\end{eqnarray*}

Why is this correct? First, let's rephrase this in terms of an operator
$\ms{fix} : (\fixtype{A} \to \fixtype{A}) \to \fixtype{A}$:
\begin{equation}
  \delta(\ms{fix}\; f) = \ms{fix}\; (\delta f \;\disc{\ms{fix}\; f})
\end{equation}

This is such a beautiful equation it can't be wrong. But let's justify it
anyway. First I'll justify it by an intuitive but informal argument. Then I'll
prove it. The intuitive argument goes like this:
\[
\begin{array}{rcll}
  \delta(\ms{fix}\; f)
  &=& \delta(f \;(\ms{fix}\;f))
  & \text{because}~\ms{fix}\; f = f\;(\ms{fix}\;f)\\
  &=& \delta f \;\disc{\ms{fix}\; f} \; \delta(\ms{fix}\; f)
  & \text{rule for}~\delta(e_1\;e_2)
\end{array}
\]

We've now found a recursive equation that describes
$\delta(\ms{fix}\;f)$ in terms of itself:
\begin{equation}\label{eqn:delta-fix}
  \delta(\ms{fix}\;f) = \delta f \;\disc{\ms{fix}\; f} \; \delta(\ms{fix}\;f)
\end{equation}

Let's apply \ms{fix} to solve the equation!
\begin{equation}
  \delta(\ms{fix}\; f)
  = \ms{fix}\,(\fn\bind{dx}\, \delta f \;\disc{\ms{fix}\;f} \;dx)
\end{equation}

This is not a proof, however, because we merely established that it was
\emph{true} that equation \ref{eqn:delta-fix} holds, not that it suffices as a
\emph{definition} of $\delta(\ms{fix}\;f)$. We haven't shown that
\emph{anything} of which equation \ref{eqn:delta-fix} holds is in fact a
derivative of $\ms{fix}\;f$. \todo{TODO: try to establish this directly instead
  of using the ``indirect'' argument below!}

So, on to a more formal approach:

Let $f' = \delta{f} \;\disc{\ms{fix}\; f}$.
Let $f_{\ms{new}} = f \oplus \delta f$.
Observe that:
\[\begin{array}{rrcll}
  &   f\;\d{x} \oplus \delta f \;\disc{\d{x}} \;dx
  &=& (f \oplus \delta f) \; (\d{x} \oplus dx)
  & \text{see Figure 4 on page 5 in Cai et al}
  \\ \implies&
  (f\;\d{x} \oplus \delta f \; \disc{\d{x}} \; dx) \ominus f\;\d{x}
  &=&
  (f \oplus \delta f) \; (\d{x} \oplus dx) \ominus f\;\d{x}
  & \text{apply $(- \ominus f\;\d{x})$ to both sides}
  \\ \implies&
  \delta f \; \disc{\d{x}} \; dx
  &=&
  (f \oplus \delta f) \; (\d{x} \oplus dx) \ominus f\;\d{x}
  & \text{because}~(a \oplus da) \ominus a = da
  \\ \implies&
  f' \; dx
  &=& f_{\ms{new}} \; (\ms{fix}\;f \oplus dx)
      \ominus f\; \disc{\ms{fix}\; f}
  & \text{substitute $\d{x} \mapsto \ms{fix}\;f$}
  \\ \implies&
  f' \; dx
  &=& f_{\ms{new}} \; (\ms{fix}\;f \oplus dx)
      \ominus \ms{fix}\; f
  & \text{because}~f\;(\ms{fix}\;f) = \ms{fix}\;f
\end{array}\]


\section{Stuff to put in this document}

\begin{enumerate}
\item Definition of \textsf{fast-fix} (see google doc).
\item Correctness criterion for $\delta$ (see google doc).
\item Lemma: for decidable semilattices, $\den{e} \oplus \den{f} = \den{e \vee
  f}$.
\item Soundness conjecture? (see google doc)
\end{enumerate}

\end{document}
