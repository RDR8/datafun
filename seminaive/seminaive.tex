\documentclass{article}
\usepackage[a4paper,margin=0.8in]{geometry}

\usepackage{datafun}

%% Allows using >{blah} and <{blah} in array formats.
\usepackage{array}

%% for \midrule
\usepackage{booktabs}

\newcommand{\dummy}{\ms{dummy}}

\begin{document}

\section{Poset terminology}

\begin{definition}[Chain]
  In a poset $A$, a \emph{chain} is a monotone map $f : \N \to A$, which we
  interpret as an infinite nondecreasing sequence of $A$s, $f(0) \le f(1) \le
  f(2) \le ...$.
\end{definition}

\begin{definition}[Strict chain]
  A chain $f : \N \to A$ is \emph{strict} if $i < j \implies f(i) < f(j)$; in
  other words, an infinite strictly increasing sequence of $A$s, $f(0) < f(1) <
  f(2) < ...$.
\end{definition}

\begin{definition}[Stops at]
  A chain $a_0 \le a_1 \le a_2 \le ...$ \emph{stops at $i$} iff $a_i$ is the
  supremum of all $a_j$. Equivalent formulations:
  \[\begin{array}{ccccc}
    a_i = \sup_j a_j
    &\Leftrightarrow& \forall(j \ge i)\ a_j \le a_i
    &\Leftrightarrow& \forall(j \ge i)\ a_i = a_j\\
  \end{array}\]
\end{definition}

\begin{definition}[Stops]
  A chain $a$ \emph{stops} iff it contains its own supremum (iff $\exists
  i\binder a~\text{stops at}~i$).
\end{definition}

\begin{observation} Strict chains don't stop. \end{observation}

\begin{definition}
  For a chain $f$, let the sequence $f^s$ (``the strictification of $f$'') be
  $f$ with all repeated elements stripped out. If $f^s$ is infinite, it is by
  construction a strict chain.
\end{definition}

%% \begin{observation}
%%   If $f$ is a strict chain, $f^s = f$, since strict chains have no repeated
%%   elements.
%% \end{observation}

\begin{lemma}
  Given a chain $a$, $a^s$ is finite iff $a$ stops (and $a^s$ is a strict chain
  iff $a$ does not stop).
\end{lemma}
\begin{proof}
  Note that the ranges of $a$ and $a^s$ are identical by construction.

  First, suppose $a^s$ is finite. Note that the last element of $a^s$ is its
  largest, and therefore the supremum of both sequences, since they have the
  same range. Therefore $a$ contains its own supremum, and stops.

  Second, suppose $a$ stops. Thus it contains the supremum of both sequences.
  Let $i$ be the index such that $a^s_i$ is this supremum. There can be no
  elements in $a^s$ after $a^s_i$. Thus $a^s$ is finite.
\end{proof}

\begin{definition}[ACC]
  A poset satisfies the \emph{ascending chain condition (ACC)} iff all chains in
  it stop, or equivalently, if it has no strict chains.
\end{definition}

``Every chain stops'' implies no strict chains exist, since every strict chain
is a chain and strict chains do not stop. Likewise, ``no strict chains exist''
implies every chain stops, since for every non-stopping chain $f$ there is a
strict chain $f^s$.

%% \begin{theorem}[ACC $\Leftrightarrow$ no strict chains]
%%   A poset $A$ satisfies ACC iff there are no strict chains on $A$.
%% \end{theorem}
%% \begin{proof}
%%   First, we show ACC implies no strict chains. Assume $A$ satisfies ACC.
%%   Consider some strict chain $f : \N \to A$. Any strict chain is a chain.
%%   Therefore by ACC $\exists i\ \forall(j \ge i)\ f(j) \le f(i)$. Letting $j = i
%%   + 1$, we have $f(i) < f(i + 1)$ by $f$'s strictness, and $f(i) \ge f(i+1)$ by
%%   ACC. Contradiction!

%%   Second, we show no strict chains implies ACC. Assume $A$ has no strict chains.
%%   Consider some (weak) chain $f : \N \to A$. Now, let the sequence $f^s$ be $f$
%%   with repeated elements stripped out, so that $f^s$ is strictly increasing, but
%%   might no longer be an infinite sequence. Since $A$ has no strict chains, we
%%   know $f^s$ is finite. Consider the index $i$ in $f$ of the first occurrence of
%%   the last (and thus greatest) element of $f^s$. By construction we have
%%   $\forall (j \ge i)\ f(j) \le f(i)$. Thus $A$ satisfies ACC.
%% \end{proof}

\begin{definition}[Downset on an element]
  The \emph{downset on $x$} in a poset $A$, written $\downintro{x : A}$ or just
  $\downintro{x}$, is the freely generated downward-closed subset of $A$
  containing $x$, namely $\setfor{y \in A}{y \le x}$.
\end{definition}

\begin{definition}[Downset]
  A \emph{downset} on a poset $A$ is a finitely-generated downward-closed subset
  of $A$; that is to say, for some \emph{finite} subset $G \finsubseteq A$, it
  is $\bigcup_{x \in G} \downintro{x}$, or equivalently $\setfor{y \in
    A}{\exists(x \in G)\ y \le x}$.
\end{definition}

Note that this definition of \emph{downset} is in fact what others might call a
\emph{finitely generated downset}. I prefer the term \emph{downward-closed set}
for the more general concept.

We will often regard a downset $D$ of $A$ as a poset, with the same ordering
relation as $A$, restricted to elements of $D$ (the ``induced ordering'').

\begin{definition}[Downset ACC]
  A poset $A$ is \emph{downset-ACC} iff every downset $D$ of $A$ satisfies
  ACC.
\end{definition}

\begin{lemma}[The union of ACC sets is ACC]\label{lemma:acc-union}
  Given a poset $\tuple{A,\le}$ and two subsets $B,C \subseteq A$, if
  $\tuple{B,\le}$ and $\tuple{C,\le}$ each satisfy ACC, then so does $\tuple{B
    \cup C, \le}$.
\end{lemma}
\begin{proof}
  Assume $B$ and $C$ satisfy ACC.
  %%
  It suffices to show that there are no strict chains in $B \cup C$.
  So consider some strict chain $f : \N \to B \cup C$.
  %%

  We can split $f(0) < f(1) < f(2) < ...$ into two strictly increasing sequences
  $b_0 < b_1 < b_2 < ...$ and $c_0 < c_1 < c_2 < ...$ by including in $b_i$ all
  and only those $f(j) \in B$ and likewise in $c_i$ all and only those $f(j) \in
  C$. Since $f$ is infinite, at least one of these sequence is infinite; WLOG,
  assume $b$ is. Thus $b$ is a strict chain in $B$! But by ACC there are no
  strict chains in $B$. Contradiction.
\end{proof}

\begin{theorem}[Elementwise ACC implies Downset ACC]
  A poset $A$ is downset-ACC if, for any $x : A$, $\downintro{x}$ satisfies ACC.
\end{theorem}
\begin{proof}
  The empty set clearly satisfies ACC. Given two subposets $D,E \subseteq A$
  which both satisfy ACC, their union $D \cup E$ also satisfies ACC by Lemma
  \ref{lemma:acc-union}. Every downset is the finite union of zero or more
  singly-generated downsets of the form $\downintro{x}$. So by induction, if
  every singly-generated downset $\downintro{x}$ satisfies ACC, so do all
  downsets.
\end{proof}



\section{Core Datafun}

\todo{We should carefully distinguish which properties are necessary to safely
  extend core Datafun --- and therefore, which proofs are ``open''. For example,
  all that should be necessary to add a type to Datafun and declare it decidable
  is that it should actually \emph{be} decidable. However, for \emph{decidable
    semilattice types}, we require that Lemma \ref{lemma:dl-boring} holds in
  order to extend the language with them.

  This means that when proving something about decidable types, we cannot do it
  by induction (or we violate extensibility), only by invoking the fact that
  they are decidable. But when proving something about decidable semilattice
  types, we can use Lemma \ref{lemma:dl-boring}. The proof of Lemma
  \ref{lemma:dl-boring} gets to use induction, but the hypothesis can't be
  strengthened (or we'd violate extensibility).}

\subsection{Syntax}

\[
\begin{array}{rccl}
  \textsf{types} & A,B,C
  &\bnfeq& A \to B \pipe A \x B \pipe A + B
  \pipe \Disc{A} \pipe \Down{\eq{A}} \pipe \tbool
  \vspace{1em}\\

  %% types where the poset relationship is decidable
  \textsf{decidable types} & \eq{A}
  &\bnfeq& \eq{A} \x \eq{B} \pipe \eq{A} + \eq{B}
  \pipe \Disc{\eq{A}} \pipe {\color{red} \Down{\eq{A}}} \pipe \tbool
  \vspace{1em}\\

  %% finite types
  \textsf{finite types} & \fin{A}
  &\bnfeq& \fin{A} \x \fin{B} \pipe \fin{A} + \fin{B}
  \pipe \Disc{\fin{A}} \pipe \Down{\fin{A}} \pipe \tbool
  \vspace{1em}\\

  %% acc types
  \textsf{acc types} & \acc{A}
  &\bnfeq& \acc{A} \x \acc{B} \pipe \acc{A} + \acc{B}
  \pipe \Disc{A} \pipe \Down{\fin{A}} \pipe \tbool
  \vspace{1em}\\

  %% downset-acc types
  \textsf{downset-acc types} & \eltacc{A}
  &\bnfeq& \eltacc{A} \x \eltacc{B} \pipe \eltacc{A} + \eltacc{B}
  \pipe \Disc{A}
  \pipe {\color{Cerulean} \Down{\fin{A}}} \pipe \Down{\Disc{A}}
  \pipe \tbool
  \vspace{1em}\\

  %% semilattice types
  \textsf{semilattice types} & \lat{A}
  &\bnfeq& A \to \lat{B} \pipe \lat{A} \x \lat{B} \pipe \Down{A} \pipe \tbool
  \vspace{1em}\\

  %% decidable semilattice types
  \textsf{decidable semilattice types} & \eqlat{A}
  &=& \eq{A} \cap \lat{A}
  \vspace{1em}\\

  %% fixpoint types
  \textsf{fixed-point types} & \fixtype{A}
  &=& \eq{A} \cap \lat{A} \cap \acc{A}
  \vspace{1em}\\

  \textsf{bounded fixed-point types} & \fixintype{A}
  &=& \eq{A} \cap \lat{A} \cap \eltacc{A}
  \vspace{1em}\\

  %% expressions
  \textsf{expressions} & e,f,g
  &\bnfeq& x \pipe \d{x} \pipe \fn\bind{x} e \pipe e\; e
  \pipe \pair{e}{e} \pipe \pi_i\; e
  \pipe \inj{i}{e} \pipe \case{e}{x}{e_1}{x}{e_2} \\
  &&\pipe& \disc{e} \pipe \letdisc{\d{x}}{e}{e} \pipe \splitsum{e}\\
  &&\pipe& \unit \pipe e \vee e \pipe \downintro{e} \pipe \downelim{x}{e}{e}\\
  &&\pipe& \etrue \pipe \efalse \pipe \when{e}{e} \pipe \ifthen{e}{e}{e}\\
  &&\pipe& \fix{x}{e} \pipe \fixin{x}{e}{e}
\end{array}
\]

\todo{Note: I try to use bold $\d{x}$ for discrete variables and ordinary script
  $x$ for monotone variables, but sometimes I screw up. Also, this is the
  opposite of the convention in the original Datafun paper.}

The ``typeclass'' rules (for decidable, finite, acc, downset-acc, semilattice,
etc.\! types) are \emph{conservative approximations} of semantic conditions.

``Decidable types'' are those whose partial ordering relation is practically
decidable; that is, given $x, y : \eq{A}$, there is a reasonable algorithm that
determines whether $x \le y$. By antisymmetry, this also makes equality $x = y$
testable at these types.

Theoretically, a function type $\under{fin}{A} \to \eq{B}$ whose domain is
finite and codomain is decidable is also decidable (it is effectively a finite
product of $\eq{B}$s). We have omitted this, as it complicates our
implementation for little practical benefit. We have similarly omitted the cases
in which function types are finite ($\fin{A} \to \fin{B}$), ACC ($\fin{A} \to
\acc{B}$), and downset-ACC ($\fin{A} \to \eltacc{B}$).

I've highlighted the decidable type ${\color{red} \Down{\eq{A}}}$ because
comparing down-sets \emph{efficiently} in general is nontrivial (impossible?).
If finite sets $\{A\}$ are implemented as $\Down{\Disc{A}}$, this may have
performance implications. A less general approach would be to consider only
$\Down{\Disc{\eq{A}}}$ to be decidable.

I've highlighted the downset-acc type ${\color{Cerulean} \Down{\fin{A}}}$
because, while correct, it seems insufficiently general. In particular it does
not cover the extremely useful special case that $\Down{\Disc{A}}$ (finite sets
of $A$s) is always downset-acc. However, $\Down{A}$ is not always downset-ACC;
consider $\Down{(\N \mathop{\under{<}{{+}}} 1)}$. \todo{I suspect the correct
  rule is that $\Down{\eltacc{A}}$ is always downset-acc, but this needs proof.
  This would generalize $\Down{\Disc{A}}$ as long as we keep the rules that
  $\Disc{A}$ is always ACC and downset-ACC.}


\subsection{Typing rules}

The typing judgment \[\J{\GP}{\GG}{e}{A}\] says that $e$ has type $A$ using
variables with types given by $\GP \cup \GG$, and moreover uses the variables in
$\GG$ in a monotone fashion.

Where possible without ambiguity, I omit the contexts $\GP;\GG$ from typing
rules.

\begin{mathpar}
  \infer{\J{\GP}{\GG}{x}{A}}{x \of A \in \GP \cup \GG}

  \infer{\fn\bind{x} e : A \to B}{\J{\GP}{\GG,x \of A}{e}{B}}

  \infer{e \; f : B}{e : A \to B & f : A}
  \\
  %% \infer{\pair{e}{f} : A \x B}{e : A & f : B}
  \infer{\pair{e_1}{e_2} : A_1 \x A_2}{e_i : A_i}

  \infer{\pi_i\; e : A_i}{e : A_1 \x A_2}

  \infer{\inj{i}{e} : A_1 + A_2}{e : A_i}

  \infer{\case{e}{x}{f_1}{x}{f_2} : B}
        {e : A_1 + A_2 & \J{\GP}{\GG, x \of A_i}{f_i}{B}}
  \\
  \infer{\J{\GP}{\GG}{\disc{e}}{\Disc{A}}}{\J{\GP}{-}{e}{A}}

  \infer{\letdisc{\d{x}}{e}{f} : B}
        { e : \Disc{A}
        & \J{\GP,\d{x}\of A}{\GG}{f}{B} }

  \infer{\splitsum{e} : \Disc{A} + \Disc{B}}
        {e : \Disc{(A + B)}}
  \\
  \infer{\unit : \lat{A}}{}

  \infer{e_1 \vee e_2 : \lat{A}}{e_i : \lat{A}}

  \infer{\downintro{e} : \Down{A}}{e : A}

  \infer{\downelim{x}{e}{f} : \lat{B}}
        { e : \Down{A}
        & \J{\GP}{\GG,x \of A}{f}{\lat{B}}}
  \\
  \infer{\etrue : \tbool}{}

  \infer{\efalse : \tbool}{}

  \infer{\when{e}{f} : \lat{A}}{e : \tbool & f : \lat{A}}

  \infer{\ifthen{e}{f_1}{f_2} : A}{e : \Disc{\tbool} & f_i : A}
  \\
  \infer{\fix{x}{e} : \fixtype{A}}{
    \J{\GP}{\GG,x\of \fixtype{A}}{e}{\fixtype{A}}}

  \infer{\fixin{x}{e}{f} : \fixintype{A}}{
    e : \Down{\fixintype{A}} &
    \J{\GP}{\GG,x \of \fixintype{A}}{f}{\fixintype{A}}}
\end{mathpar}


\section{A Theory of Changes for Core Datafun}

\subsection{Change types}

For each type $A$ we define a change type $\GD A$.

\[\begin{array}{rcl>{\quad\quad}rcl}
  \GD(A \to B) &=& \Disc{A} \to \Delta A \to \Delta B\\
  \GD(A \x B) &=& \GD A \x \GD B\\
  \GD(A + B) &=& \GD A + \GD B\\
  \GD(\Disc{A}) &=& \Disc{\GD A}\\
  \GD(\Down{A}) &=& \Down{A}\\
  \GD \tbool &=& \tbool
\end{array}\]

We also define associated operators $\oplus : A \to \GD A \to A$, $\ominus : A
\to A \to \Delta A$ and $\zero : A \to \Delta A$. Note, however, the
definitions of these operators \emph{are not well-typed Datafun terms}. \todo{I
  do not believe there exists a way to assign them tones that is compatible with
  Datafun's type system; every way I've tried fails. But I have not proved
  this.}

As for the semantic tonal behavior of these operators, I believe I know this
much:
\begin{itemize}
\item $x \oplus dx$ is monotone in $dx$.
\item $x \ominus y$ is monotone in $x$ and antitone in $y$.
\item $\zero$ is discrete; at function type, it finds the derivative of its
  argument, and a function that is larger pointwise does not necessarily have a
  derivative that is larger pointwise.
\end{itemize}

But is $\oplus$ monotone in its first argument? I'm not sure. It seems wrong to
contemplate changing its first argument without also changing its second ---
really it should have a dependent type.

\begin{center}
\[
\scalebox{0.85}{\(
\arraycolsep=1.5em
\begin{array}{cccc}
  \textbf{Type}
  & {\textbf{Definition of}~\oplus}
  & {\textbf{Definition of}~\ominus}
  & {\textbf{Definition of}~\zero}
  \\ \midrule
  A \to B
  & (f \oplus df)\; x = f\; x \oplus df\; x\; (\zero\; x)
  & (f \ominus g)\; x \;dx = f\; (x \oplus dx) \ominus g \; x
  & \zero\; f\; x\; dx = f\; (x \oplus dx) \ominus f\; x
  \\
  A \x B
  & \pair{x}{y} \oplus \pair{dx}{dy} = \pair{x \oplus dx}{y \oplus dy}
  & \pair{a}{x} \ominus \pair{b}{y} = \pair{a \ominus b}{x \ominus y}
  & \zero \; \pair{x}{y} = \pair{\zero\; x}{\zero\; y}
  \\
  A + B
  & \inj{i}{x} \oplus \inj{i}{dx} = \inj{i}{(x \oplus dx)}
  & \inj{i}{x} \ominus \inj{i}{y} = \inj{i}{x \ominus y}
  & \zero\; (\inj{i}{x}) = \inj{i}{(\zero\;x)}
  \\
  \Disc{A}
  & \disc{x} \oplus \disc{dx} = \disc{x \oplus dx}
  & \disc{x} \ominus \disc{y} = \disc{x \ominus y}
  & \zero\; \disc{x} = \disc{\zero\; x}
  \\
  \Down{A}
  & x \oplus y = x \vee y
  & x \ominus y = x
  & \zero\; x = \unit
  \\
  \tbool
  & x \oplus y = x \vee y
  & x \ominus y = x
  & \zero\; x = \unit
\end{array}
\)}
\]
\end{center}

These should satisfy the following laws:
\begin{eqnarray}
  x \le y \quad\implies\quad
  y &=& x \oplus (y \ominus x)\\
  x &=& x \oplus \zero\; x
\end{eqnarray}

\todo{TODO: Prove these laws hold.}

\todo{TODO: Note about ``erasure''/invalid changes. Moreover, at $\Disc{A}$
  type, only valid changes are zero changes.}

\todo{TODO: Note about efficiency of computing $\oplus$, $\ominus$, $\zero$,
  and which ones we actually need to compute in the implementation. Define
  efficiently computable $(- \ominus \unit)$ operator for decidable types, and
  point out that $\zero$ is efficiently computable for decidable types.}

%% Zero on decidable types.
%% Zero on decidable types:
%% \[\arraycolsep=1.5em
%% \begin{array}{c|c}
%%   \eq{A} \x \eq{B}
%%   & \zero\; (x,y) = (\zero\; x, \zero\; y)
%%   \\
%%   \eq{A} + \eq{B}
%%   & \zero\; (\inj{i}{x}) = \inj{i}(\zero\; x)\\
%%   \Disc{\eq{A}}
%%   & \zero\;(\disc{x}) = \disc{(\zero\; x)}\\
%%   \Down{\eq{A}} & \zero\;x = \unit\\
%%   \tbool & \zero\; x = \unit
%% \end{array}
%% \]


%% Some lemmas.
\begin{lemma}[Changes on a semilattice form a semilattice]
  $\GD \lat{A}$ is a semilattice type.

  \todo{TODO: do we actually need/use this lemma?}
\end{lemma}
\begin{proof}
  By induction on the cases:
  \begin{eqnarray*}
    \GD(A \to \lat{B}) &=& \Disc{A} \to \GD A \to \GD \lat{B}\\
    \GD(\lat{A} \x \lat{B}) &=& \GD \lat{A} \x \GD \lat{B}\\
    \GD(\Down{A}) &=& \Down{A}\\
    \GD 2 &=& 2
  \end{eqnarray*}
\end{proof}

\begin{lemma}[Changes on decidable semilattices are boring]\label{lemma:dl-boring}
  For any decidable semilattice type $\eqlat{A}$, $\GD \eqlat{A} = \eqlat{A}$,
  and moreover the following laws hold:
  \begin{eqnarray*}
    x \oplus y &=& x \vee y\\
    x \ominus y &=& x\\
    \zero\; x &=& \unit
  \end{eqnarray*}
\end{lemma}
\begin{proof}
  By induction on the cases:
  \[\begin{array}{rcl}
    \GD(\eqlat{A} \x \eqlat{B}) &=& \GD \eqlat{A} \x \GD \eqlat{B}\\
    \GD(\Down{\eq{A}}) &=& \Down{\eq{A}}\\
    \GD \tbool &=& \tbool
  \end{array}\]

  And, for the operations:
  \[\arraycolsep=0.75em
  \begin{array}{c|ccc}
    \eqlat{A} \x \eqlat{B}
    & (x,y) \oplus (dx,dy) = (x \oplus dx, y \oplus dy)
    & (a,x) \ominus (b,y) = (a \ominus b, x \ominus y)
    & \zero\; (x,y) = (\zero\; x, \zero\; y)\\
    \Down{\eq{A}}
    & x \oplus y = x \vee y
    & x \ominus y = x
    & \zero\;x = \unit\\
    \tbool
    & x \oplus y = x \vee y
    & x \ominus y = x
    & \zero\;x = \unit\\
  \end{array}
  \]
\end{proof}


\subsection{Derivatives}

We wish to define an operator $\delta$ on typing derivations (or if possible, on
well-typed terms) such that the following holds:
\[\infer{\J{\GP,\GD\GP,\GG}{\GD\GG}{\delta e}{\Delta A}}
        {\J{\GP}{\GG}{e}{A}}
\]

As a matter of convention, prefixing a variable with $d$ refers to the
corresponding variable of its change type. That is, if $x \of A \in \GP \cup
\GG$, then $dx \of \GD A \in \GD\GP \cup \GD\GG$. We also make implicit use of
weakening and monotone-to-discrete weakening (that is, if
$\J{\GP}{\GG_1,\GG_2}{e}{A}$, then $\J{\GP,\GG_1}{\GG_2}{e}{A}$).

\todo{\indent Furthermore, if $e : A$ originally, then in the the $\delta$-context,
  $\disc{e} : \Disc{A}$ for free, since all the variables $e$ uses are now
  discrete. Can/do we take advantage of this?} {\color{ForestGreen} Yes we do!
  See the green $(\disc{e})$ in the case for \textsf{when-then} below.}

\[
\begin{array}{lcll}
  \delta x &=& dx\\
  \delta \d{x} &=& \d{dx}\\
  \delta(\fn\bind{x} e) &=&
  \fn\bind{y} \letdisc{\d{x}}{y} {\fn\bind{dx} \delta e}
  \qquad\text{(for fresh $y$)}\\
  \delta(e\;f) &=& \delta e \; f \; \delta f\\
  \delta \pair{e}{f} &=& \pair{\delta{e}}{\delta{f}}\\
  \delta(\pi_i\; e) &=& \pi_i\; \delta{e}\\
  \delta(\inj{i}{e}) &=& \inj{i}{\delta{e}}\\
  \delta(\case{e}{x}{f}{y}{g})
  %% &=& \case{\splitsum{\color{ForestGreen} \disc{e}}}
  %%       {\disc{\d{x}}}{\case{\delta e}{dx}{\delta f}{\_}{\todo{\ms{abort!}}}}
  %%       {\disc{\d{x}}}{\textit{(symmetric case)}}\\
  &=& \ms{case}(\splitsum{\color{ForestGreen}\disc{e}};\\
   && \phantom{\ms{case}\ }
      \bind{\disc{\d{x}}}
      \letv{dx}{\case{\delta e}{dx}{dx}{\_}{\dummy\;\d{x}}} \delta f;\\
   && \phantom{\ms{case}\ }
      \bind{\disc{\d{y}}}
      \letv{dy}{\case{\delta e}{\_}{\dummy\;\d{y}}{dy}{dy}} \delta g)\\
  \delta\disc{e} &=& \disc{\delta e}\\
  \delta(\letdisc{\d{x}}{e} f) &=&
  \letdisc{\d{x}}{e}
    \letdisc{\d{dx}}{\delta e} \delta f\\
  \delta(\splitsum{e}) &=&
  %% want type: Δ□A + Δ□B = □ΔA + □ΔB
  %% e : □(A + B)
  %% δe : □(ΔA + ΔB)
  %% splitsum δe : □ΔA + □ΔB
  \splitsum{\delta e}\\
  \delta \unit &=& \unit\\
  \delta(e \vee f) &=& \delta e \vee \delta f
  \qquad \text{(this is the critical over-approximation)}\\
  \delta(\downintro{e}) &=& \unit\\
  \delta(\downelim{\d{x}}{e}{f}) &=& \text{\todo{see below}}\\
  \delta(\etrue) &=& \efalse\\
  \delta(\efalse) &=& \efalse\\
  \delta(\when{e}{f})
  &=& \ifthen{\color{ForestGreen} \disc{e}}{\delta f}{
    \when{\delta e}{(f \oplus \delta f) \ominus \unit}}
  \qquad \text{\color{red} see below}\\
  \delta(\ifthen{e}{f}{g}) &=& \ifthen{e}{\delta f}{\delta g}\\
  \delta(\fix{x}{e}) &=&
  \letdisc{\d{x}}{\disc{\fix{x} e}}{\fix{dx} \delta e}\\
  \delta(\fixin{x}{e}{f}) &=& \text{\TODO}
\end{array}
\]

At equality types, $\delta(\downelim{x}{e}{f})$ has the following definition:

\[\begin{array}{rcl}
  \delta(\downelim{x}{e}{f})
  &=& \phantom{\vee~} (\downelim{x}{e}{\ms{let}~dx = \zero\; x ~\ms{in}~ \delta f})
  \\ && \vee~ (\downelim{x}{\delta e}{\ms{let}~dx = \zero\; x ~\ms{in}~
    (f \oplus \delta f) \ominus \unit})
\end{array}\]

\todo{\todo{FIXME}: this doesn't type check! In $\downelim{x}{e} \letv{dx}{\zero\;
  x}{\delta f}$, the variable $x$ is bound monotone, but it needs to be
discrete! we have $e : \Disc{\Down{A}}$, but that's not the same as
$\Down{\Disc{A}}$. Maybe we need an axiom:
\[ \ms{suprema} : \Disc{\Down{\eq{A}}} \to \Down{\Disc{\eq{A}}} \]

But what about the second case? Same problem! And it's not clear it can be fixed
this time! Uh-oh. Are there any examples where this computes the *wrong*
derivative?}

\todo{TODO: Explain/show that $\oplus$, $(- \ominus \unit)$, and \zero{} are
  definable, typeable, and efficiently computable at these types!}

Translation of $\downelim{x}{e}{f}$ at \emph{non-equality types}, however, is
type-directed:

\[\begin{array}{lcll}
  \delta(\downelim{x}{e}{f} : A \to \lat{B})
  &=& \fn\bind{y} \downelim{x}{e}{f\; y}\\
  \delta(\downelim{x}{e}{f} : \lat{A} \x \lat{B})
  &=& \pair{\delta(\downelim{x}{e}{\pi_1\; f})}
  {\delta(\downelim{x}{e}{\pi_2\; f})}
\end{array}\]

\emph{Hypothesis}: For $a : \lat{A}$ and $da : \GD\lat{A}$ a valid change to
$a$:
\begin{equation*}
  (a \oplus da) \ominus \unit = (a \ominus \unit)
  \vee da
\end{equation*}

\emph{Observation}: Consider $(\when{e}{f})$ for $f : A \to \lat{B}$. We can
rewrite this as $(\fn\bind{x} \when{e}{f\; x})$. This turns a \ms{when} at type
$A \to \lat{B}$ into one at type $\lat{B}$. By extending this we can rewrite
away all uses of \ms{when} at functional types, in the same manner as we can
rewrite away uses of $\bigvee$ at functional type.

\todo{\par TODO: Proofs which Neel \& I worked out last time.}


\subsubsection{Dummy values}

The derivative of $\ms{case}$ has branches we know semantically cannot occur;
but to appease the type system, we need to put an expression in those branches
of the appropriate type. Instead of introducing an \ms{abort} construct, which
would complicate our semantics, we generate an expression of the appropriate
type using a type-indexed dummy-value function $\dummy{} : A \to \Delta{A}$.

\[\begin{array}{lcl}
\dummy\; (x : \tbool) &=& \efalse\\
\dummy\; (x : \Down{A}) &=& \unit\\
\dummy\; \pair{x}{y} &=& \pair{\dummy\;x}{\dummy\;y}\\
\dummy\; (\inj{i}{x}) &=& \inj{i}{(\dummy\;x)}\\
\dummy\; \disc{\d{x}} &=& \disc{\dummy\; \d{x}}\\
\dummy\; (f : A \to B) &=& \fn x\,dx\binder\, \dummy\;(f\;x)
\end{array}\]

This is a hack to simplify our metatheory. A real implementation would not do
this.

\todo{NB. To add a type to Datafun, we must extend \dummy{} appropriately.}


\subsubsection{Justifying derivatives of fixed points}

Our rule for the derivative of a fixed point is:
\begin{eqnarray*}
  \delta(\fix{x} e)
  &=& \letdisc{\d{x}}{\disc{\fix{x} e}}{\fix{dx} \delta e}\\
  &=& \fix{dx}
      (\fn \d{x}\, dx\binder \delta e)
      \; \disc{\fix{x} e}
      \; dx\\
  &=& \fix{dx} \delta(\fn\bind{x} e)
      \; \disc{\fix{x} e}
      \; dx
\end{eqnarray*}

Why is this correct? First, let's rephrase this in terms of an operator
$\ms{fix} : (\fixtype{A} \to \fixtype{A}) \to \fixtype{A}$:
\begin{equation}
  \delta(\ms{fix}\; f) = \ms{fix}\; (\delta f \;\disc{\ms{fix}\; f})
\end{equation}

This is such a beautiful equation it can't be wrong. How did we arrive at this
equation? Well,
\[
\begin{array}{rcl>{\hspace{1em}}l}
  \delta(\ms{fix}\; f)
  &=& \delta(f \;(\ms{fix}\;f))
  & \text{because}~\ms{fix}\; f = f\;(\ms{fix}\;f)\\
  &=& \delta f \;\disc{\ms{fix}\; f} \; \delta(\ms{fix}\; f)
  & \text{rule for}~\delta(e_1\;e_2)
\end{array}
\]

We've now found a recursive equation that describes
${\color{blue}\delta(\ms{fix}\;f)}$ in terms of itself:
\begin{equation}\label{eqn:delta-fix}
  {\color{blue} \delta(\ms{fix}\;f)}
  = \delta f \;\disc{\ms{fix}\; f} \; {\color{blue}\delta(\ms{fix}\;f)}
\end{equation}

Let's apply \ms{fix} to solve the equation!
\begin{equation*}
  \delta(\ms{fix}\; f)
  =
  \ms{fix}\,(\fn\bind{\color{blue}dx}
  \delta f \;\disc{\ms{fix}\;f} \;{\color{blue}dx})
\end{equation*}

Unfortunately, this is not a proof of correctness. We merely established that it
was \emph{true} that equation \ref{eqn:delta-fix} holds, not that it suffices as
a \emph{definition} of $\delta(\ms{fix}\;f)$. The correctness criterion for
$\delta(\ms{fix}\; f)$ is roughly:

\begin{equation}
  \ms{fix}\;f \oplus \delta(\ms{fix}\;f)
  = (\mfix\;f)\sub{\gamma \oplus \delta\gamma/\gamma}
\end{equation}

That is, an expression plus its derivative equals the original expression
computed with updated free variables. Let's prove this holds for our proposed
definition!

\begin{theorem}
  \(\mfix\; f \oplus \mfix\;(\delta f \; \disc{\mfix\;f})
  = (\mfix\; f)\sub{\gamma \oplus \delta\gamma/\gamma}
  \)
\end{theorem}
\begin{proof}
  First, we require that we have a correct derivative for $f$, and therefore:
  \begin{eqnarray*}
    (\mfix\; f)\sub{\gamma\oplus\delta\gamma/\gamma}
    &=& \mfix\;(f\sub{\gamma\oplus\delta\gamma/\gamma})\\
    &=& \mfix\;(f \oplus \delta f)
  \end{eqnarray*}

  So it suffices to show:
  \begin{equation}
    \mfix\; f \oplus \mfix\;(\delta f \; \disc{\mfix\;f})
    = \mfix\; (f \oplus \delta f)
  \end{equation}

  We'll do this by showing inequalities in each direction. First, we'll show
  that $\mfix\;f\oplus\mfix\;(\delta f\;\disc{\mfix\;f})$ is a fixed point of $f
  \oplus \delta f$. Since $\mfix\;(f\oplus \delta f)$ is the least such fixed
  point, this will establish one direction of our inequality:
  \[
  \begin{array}{rcll}
    & (f \oplus \delta f)
    \; (\mfix\;f \oplus \mfix\;(\delta f\;\disc{\mfix\;f}))
    \\
    =& f\; (\mfix\;f) \oplus \delta f \;\disc{\mfix\;f} \;
    (\mfix\; (\delta f \;\disc{\mfix\;f}))
    & \text{\todo{property of $\delta$ and $\oplus$; see Figure 4 on page 5 in Cai et all}}
  \end{array}
  \]

   First, consider the left-hand side.
  Because of the way fixed points are computed, we can pick $i$ such that \(
  \mfix\;(\delta f \;\disc{\mfix\;f}) = (\delta f \; \disc{\mfix\;f})^i \;\unit
  \). Applying the crucial Lemma \ref{lemma:crux} with $dx = \unit$, we have
  \[\begin{array}{rcll}
  \mfix\;f\oplus\mfix\;(\delta f \;\disc{\mfix\;f})
  &=& \mfix\;f\oplus(\delta f \; \disc{\mfix\;f})^i \;\unit
  & \text{by our choice of $i$}\\
  &=& (f \oplus \delta f)^i \; (\mfix\;f \oplus \unit)
  & \text{Lemma \ref{lemma:crux} with $dx = \unit$}\\
  &=& (f \oplus \delta f)^i \; (\mfix\;f)
  & \text{$\unit$ is a unit of $\oplus$ by Lemma \ref{lemma:dl-boring}}\\
  &\le& (f \oplus \delta f)^i \; (\mfix\;(f \oplus \delta f))
  & \text{monotonicity and Lemma \ref{lemma:oplus-increasing}}\\
  &=& \mfix\;(f \oplus \delta f)
  & \text{it's a fixed point}
  \end{array}\]

  So transitively, $\mfix\;f\oplus\mfix\;(\delta f \;\disc{\mfix\;f}) \le
  \mfix\;(f \oplus\delta f)$. It remains to show the other direction.

  We know $\mfix\;(f \oplus \delta f) = (f \oplus \delta f)^i \; \unit$ for some
  $i$. Then, again applying the crucial Lemma \ref{lemma:crux}:
  \[
  \begin{array}{rcll}
    \mfix\;(f \oplus \delta f)
    &=& (f \oplus \delta f)^i\; \unit\\
    &\le& (f \oplus \delta f)^i \; (\mfix\;f \oplus \unit)
    & \text{monotonicity}\\
    &=& \mfix\;f \oplus (\delta f \;\disc{\mfix\;f})^i \;\unit
    & \text{Lemma \ref{lemma:crux} with $dx = \unit$}
  \end{array}
  \]

  %% \[\begin{array}{rcll}
  %%   f &\le& f \oplus \delta f
  %%   & \text{Lemma \ref{lemma:oplus-increasing}}\\
  %%   \mfix\;f &\le& \mfix\;(f\oplus\delta f)
  %%   & \text{monotonicity of $\mfix$}\\
  %%   \mfix\;f \oplus \unit &\le& \mfix\;(f \oplus \delta f)
  %%   & \text{$\unit$ is the unit of $\oplus$, by Lemma \ref{lemma:dl-boring}}\\
  %%   (f\oplus\delta f)^i\; (\mfix\;f\oplus\unit)
  %%   &\le&
  %%   (f \oplus\delta f)^i\; (\mfix\;(f\oplus \delta f))
  %%   & \text{monotonicity of $f \oplus \delta f$}\\
  %%   (f\oplus\delta f)^i\; (\mfix\;f\oplus\unit)
  %%   &\le& \mfix\;(f\oplus \delta f)
  %%   & \text{it's a fixed point!}
  %% \end{array}\]
  %% Now we apply the crucial Lemma \ref{lemma:crux}:

\end{proof}

\begin{theorem}[Soundness of ordering on change types]
  For any $dx, dx' : \Delta A$, if $dx \le dx'$, then for any $x : A$, we have
  $x \oplus dx \le x \oplus dx'$.
\end{theorem}
\begin{proof}
  \todo{TODO. This seems like it should be true. Note that we don't \emph{need}
    this to be true for all types, just for fixed-point types $\fixtype{A}$, but
    it would be surprising if it weren't true generally.}
\end{proof}

\begin{lemma}
  $x \le x \oplus dx$
  \label{lemma:oplus-increasing}
\end{lemma}
\begin{proof}
  \todo{TODO.}
\end{proof}

%% \begin{lemma}
%%   If $a \le \mfix\;f$ then $\forall\bind{i} f^i\;a \le \mfix\;f$.
%%   \label{lemma:fix-stays-bigger}
%% \end{lemma}
%% \begin{proof}
%%   By monotonicity, $f^i\; a \le f^i \;(\mfix\;f)$. But since $\mfix\;f$ is a
%%   fixed point of $f$, $f^i\;(\mfix\;f) = \mfix\;f$.
%% \end{proof}

%% \begin{lemma}[jcreed's lemma, adapted]
%%   If $a \le \mfix\;f$ and $\mfix\;f = f^i\;\unit$, then $f^i\;a = \mfix\;f$.
%%   \label{lemma:jcreed}
%% \end{lemma}
%% \begin{proof}
%%   Firstly, by monotonicity $f^i\;a \le f^i\;(\mfix\;f) = \mfix\;f$ (since
%%   $\mfix\;f$ is a fixed point). Second, since $\unit \le a $, by monotonicity
%%   $\mfix\;f = f^i\;\unit \le f^i\;a$.
%% \end{proof}

\begin{lemma}[Crux]
  For any $i \in \N$ and $dx : \Delta \fixtype{A}$ \todo{(TODO: we might need
    $dx$ to be a valid change, actually)}, we have
  \[
  \mfix\;f \oplus (\delta f \;\disc{\mfix\;f})^i\;dx
  =
  (f \oplus \delta f)^i \;(\mfix\; f \oplus dx)
  \]
  \todo{TODO: Explain this in English somehow? I don't have an intuition for why
    this should be so, but I feel like there is an intuitive explanation waiting
    to be found.}
  \label{lemma:crux}
\end{lemma}
\begin{proof}
  By induction on $i$.

  \textbf{Base case, $i = 0$:} Trivial: \( \mfix\;f \oplus dx = \mfix\;f \oplus
  dx \).

  \textbf{Inductive case:} We know inductively that, for any $dx$,
  \[
  \mfix\;f \oplus (\delta f \;\disc{\mfix\;f})^i\;dx
  =
  (f \oplus \delta f)^i \;(\mfix\; f \oplus dx)
  \]

  We show the same for $i+1$:
  \[\begin{array}{cl>{\hspace{1em}}l}
     & \mfix\;f \oplus (\delta f \;\disc{\mfix\;f})^{i+1}\;dx\\
    =& \mfix\;f\oplus (\delta f \;\disc{\mfix\;f})^i
    \;(\delta f \;\disc{\mfix\;f} \;dx)\\
    =& (f \oplus \delta f)^i \;
    (\mfix\;f \oplus \delta f \;\disc{\mfix\;f}\; dx)
    & \text{by IH, substituting \((\delta f \;\disc{\mfix\;f}\;dx\)) for $dx$}\\
    =& (f \oplus \delta f)^i \;
    (f\;(\mfix\;f) \oplus \delta f\; \disc{\mfix\;f}\; dx)
    & \text{since $\mfix\;f = f\;(\mfix\;f)$}\\
    =& (f \oplus \delta f)^i \;
    ((f \oplus \delta f)\;(\mfix\;f \oplus dx))
    & \text{\todo{property of $\delta f$; see Figure 4 on page 5 in Cai et
        al}}\\
    =& (f \oplus \delta f)^{i+1} \; (\mfix\;f \oplus dx)
  \end{array}\]

\end{proof}

\begin{lemma} For $f : A \to B$, $x : A$, $df : \Delta (A \to B)$, and $x :
  \Delta A$, where $df$ and $dx$ are valid changes to $f$,$x$ respectively (see
  section on ``Dependent change types'', below), we have:
  \[(f \oplus df) \; (x \oplus dx) = f\;x \oplus df\;x\;dx\]
\end{lemma}
\begin{proof}
  \todo{TODO. See figure 4, page 5, in Cai et al.}
\end{proof}


%% So, on to a more formal approach:

%% Let $f' = \delta{f} \;\disc{\ms{fix}\; f}$.
%% Let $f_{\ms{new}} = f \oplus \delta f$.
%% Observe that:
%% \[\begin{array}{rrcll}
%%   &   f\;\d{x} \oplus \delta f \;\disc{\d{x}} \;dx
%%   &=& (f \oplus \delta f) \; (\d{x} \oplus dx)
%%   & \text{see Figure 4 on page 5 in Cai et al}
%%   \\ \implies&
%%   (f\;\d{x} \oplus \delta f \; \disc{\d{x}} \; dx) \ominus f\;\d{x}
%%   &=&
%%   (f \oplus \delta f) \; (\d{x} \oplus dx) \ominus f\;\d{x}
%%   & \text{apply $(- \ominus f\;\d{x})$ to both sides}
%%   \\ \implies&
%%   \delta f \; \disc{\d{x}} \; dx
%%   &=&
%%   (f \oplus \delta f) \; (\d{x} \oplus dx) \ominus f\;\d{x}
%%   & \text{because}~(a \oplus da) \ominus a = da
%%   \\ \implies&
%%   f' \; dx
%%   &=& f_{\ms{new}} \; (\ms{fix}\;f \oplus dx)
%%       \ominus f\; \disc{\ms{fix}\; f}
%%   & \text{substitute $\d{x} \mapsto \ms{fix}\;f$}
%%   \\ \implies&
%%   f' \; dx
%%   &=& f_{\ms{new}} \; (\ms{fix}\;f \oplus dx)
%%       \ominus \ms{fix}\; f
%%   & \text{because}~f\;(\ms{fix}\;f) = \ms{fix}\;f
%% \end{array}\]


\section{Fixed points}

\[\begin{array}{l}
  \textsf{fast-fix} ~:~
  (\Disc{\fixtype{A}} \to \Delta\fixtype{A} \to \Delta\fixtype{A})
  \to \fixtype{A} \to \Delta\fixtype{A} \to \fixtype{A}\\
  \textsf{fast-fix}\; \mi{df}\; \mi{current}\; \mi{change} =\\
  \quad \textbf{let}~ {\mi{next} = \mi{current} \oplus \mi{change}}
  ~\textbf{in}\\
  \quad \textbf{if}~ \mi{next} \le \mi{current}
  ~\textbf{then}~ \mi{current}\\
  \quad \textbf{else}~ \textsf{fast-fix}\; \mi{df}\; \mi{next}
  \;(\mi{df}\; \mi{current}\; \mi{change})\\
  \\
  \textsf{fast-fix}
  \in ((x : \Disc{L}) \to \Delta(L, x) \to \Delta(L, x)) \to L
  \\
  \textsf{fast-fix} \; df =\\
  \quad\textbf{let}~ \textsf{loop} \in (x : L) \to \Delta(L, x) \to L\\
  \quad\phantom{\textbf{let}~} \textsf{loop} \;x \;dx =\\
  \quad\phantom{\textbf{let}~}\quad
  \textbf{let}~ x' = x \oplus dx ~\textbf{in}\\
  \quad\phantom{\textbf{let}~}\quad
  \textbf{if}~ x' \le x ~\textbf{then}~ x\\
  \quad\phantom{\textbf{let}~}\quad
  \textbf{else}~\textsf{loop} \;x' \;(df \; x \; dx)\\
  \quad\textbf{in}~ \textsf{loop} \; \unit \; (f \; \unit \ominus \unit)
\end{array}\]


\section{Dependent change types}

We will define the following type-indexed sets and operators:

\[\begin{array}{ccccl}
  \Changes{A}{a} &\subseteq& |\Den{\GD{A}}|
  &\text{for}& a \in \Den{A}
  \\
  a \oplus_A da &\in& \Den{A}
  &\text{for}& a \in \Den{A} ~\text{and}~ da \in \Changes{A}{a}
  \\
  b \ominus_A a &\in& \Changes{A}{a}
  &\text{for}& a, b \in \Den{A} ~\text{and}~ a \le b
  \\
  \zero_A\; a &\in& \Changes{A}{a}
  &\text{for}& a \in \Den{A}
\end{array}\]

\zero{} is simply syntax sugar; $\zero_A\; x = x \ominus_A x$. The other three
are defined mutually, by induction on types. First we give the rules for
$\Changes{A}{a}$:

\[
\def\arraystretch{1.2}
\begin{array}{lcl}
  \Changes{\tbool}{\pwild} &=& \Den{\tbool}
  \\
  \Changes{\Down{A}}{\pwild} &=& \Den{\Down{A}}
  \\
  \Changes{A_1 + A_2}{\inj{i}{x}}
  &=& \setfor{\inj{i}{dx}}{dx \in \Changes{A_i}{dx}}
  %% \\
  %% \inj{i}{dx} \in \Changes{A_1 + A_2}{\inj{i}{x}}
  %% &\iff& dx \in \Changes{A_i}{x}
  \\
  \Changes{A \x B}{\pair{a}{b}}
  &=& \Changes{A}{a} \x \Changes{B}{b}
  \\
  \Changes{\Disc{A}}{a}
  &=& \setfor{dx \in \Changes{A}{a}}{x \oplus_A dx = x}
  \\
  df \in \Changes{A \to B}{f}
  &\Leftrightarrow&
  \forall({a,b \in \Den{A}},\, da \in \Changes{A}{a},\, db \in \Changes{A}{b})\\
  &&\phantom{{}\wedge{}}
  df\; a\; da \in \Changes{B}{f\; a}
  \wedge df\;b\;db \in \Changes{B}{f\; b}
  %% \\
  %% &&{}\wedge (a \mapsto f\; a \oplus_B df\; a \; (\zero_A\; a))
  %% ~\text{is monotone}
  \\
  &&{}\wedge (a \oplus da \le b \oplus db \implies
  f\;a \oplus df\;a\;da \le f\;b \oplus df\;b\;db)
\end{array}
\]

The condition defining $df \in \Changes{A \to B}{f}$ can be phrased as requiring
that the map $(a, da) \mapsto (f\;a, df\;a\;da)$ is monotone when we order its
domain and codomain by $(a,da) \le (b,db) \iff a \oplus da \le b \oplus db$.
\todo{FIXME: see figure 4, page 5 in Cai et al. They have a different
  condition/semantics for $\Delta(A \to B)$, namely: $df \in \Changes{A \to
    B}{f}$ iff $(f \oplus df)\;(a \oplus da) = f\;a\oplus df\;a\;da$. Can ours
  prove theirs?}

And the operators:
\begin{center}
  \scalebox{1}{\(
  \begin{array}{cccc}
    \textbf{Type} & \oplus & \ominus %% & \zero
    \\ \midrule
    \tbool
    & a \oplus da = a \vee da
    & b \ominus a = b
    %% & \zero\; a = \ms{false}
    \\
    \Down{A}
    & a \oplus da = a \cup da
    & b \ominus a = b
    %% & \zero\; a = \emptyset
    \\
    A + B
    & \inj{i}{a} \oplus \inj{i}{da} = \inj{i}{a \oplus da}
    & \inj{i}{b} \ominus \inj{i}{a} = \inj{i}{b \ominus a}
    %% & \zero\; (\inj{i}{a}) = \inj{i}{\zero\; a}
    \\
    A \x B
    & \pair{a}{b} \oplus \pair{da}{db} = \pair{a \oplus da}{b \oplus db}
    & \pair{b}{y} \ominus \pair{a}{x} = \pair{b \ominus a}{y \ominus x}
    %% & \zero\;\pair{a}{b} = \pair{\zero\; a}{\zero\; b}
    \\
    \Disc{A}
    & a \oplus da = a
    & b \ominus_{\Disc{A}} a = \zero_{A}\; a
    %% & \zero_{\Disc{A}}\; a = \zero_{A}\; a
    \\
    A \to B
    & (f \oplus df)\; x = f\; x \oplus df\; x \; (\zero\; x)
    & (g \ominus f)\; x\; dx = g\; (x \oplus dx) \ominus f\; x
    %% & (\zero\; f)\; x\; dx = f\; (x \oplus dx) \ominus f\; x
  \end{array}
  \)}
\end{center}

Although we define $\Changes{A}{a}$ as a subset of the elements $\Den{\GD{A}}$,
we consider it to be a poset with the induced ordering.

We will show the following:

\begin{enumerate}
\item If $a \le b$ then $a \oplus_A (b \ominus_A a) = b$. From this it
  follows that $a \oplus_A \zero_A\; a = a$.

\item $a \oplus_A da$ is monotone in $da$. That is: for any $a \in \Den{A}$ and
  $da, db \in \Changes{A}{a}$, if $da \le db$ in $\Den{\GD{A}}$, then $a
  \oplus_A da \le a \oplus_A db$ in $\Den{A}$.

\item \todo{(it should be true, but do we need to show this?)} $b \ominus_A a$ is
  monotone in $b$.
\end{enumerate}

%% NB. One might think we could also say something like: ``$\zero_A\; a$ is the
%% least element of $\Changes{A}{a}$''. This might be true for $\zero$ as defined
%% (although I'm not sure it is), but it is not true of zero changes in general:
%% $\{5\}$ is a zero-change on $\{5\}$, but not the least element of
%% $\Changes{\Set{{\N}}}{\{5\}}$; the empty set (also a zero-change) is smaller.

\begin{lemma}
  If $a \le b$ then $a \oplus_A (b \ominus_A a) = b$.
\end{lemma}

\begin{proof}
  By induction on $A$:
  \begin{description}
    \item[Case $\tbool$]
      \begin{equation*}
      a \oplus_\tbool (b \ominus_\tbool a) = a \vee b = b
      \end{equation*}
      Where $a \vee b = b$ follows from $a \le b$.

    \item[Case $\Down{A}$]
      \begin{equation*}
        a \oplus_{\Down{A}} (b \ominus_{\Down{A}} a)
        = a \cup b
        = b
      \end{equation*}
      Where $a \cup b = b$ follows from $a \le b$, i.e. $a \subseteq b$.

    \item[Case $A_1 + A_2$]
      \begin{equation*}
        \inj{i}{a} \oplus (\inj{i}{b} \ominus \inj{i}{a})
        = \inj{i}{(a \oplus_{A_i} (b \ominus_{A_i} a))}
        = \inj{i}{b}  \quad\text{(by IH)}
      \end{equation*}

      We know the subscript $i$ is identical for $\inj{i}{a}$ and $\inj{i}{b}$
      because $\inj{i}{a} \le \inj{j}{b} \implies i = j$.

    \item[Case $A \x B$]
      \begin{equation*}
        \pair{a}{x} \oplus (\pair{b}{y} \ominus \pair{a}{x})
        = \pair{a \oplus (b \ominus a)}{x \oplus (y \ominus x)}
        = \pair{b}{y} \quad\text{(by IH)}
      \end{equation*}

    \item[Case $\Disc{A}$]
      \begin{equation*}
        a \oplus (b \ominus a) = a = b
      \end{equation*}
      Where $a = b$ follows from $a \le b$ and discreteness.


    \item[Case $A \to B$]
      \[\begin{array}{rcll}
      (f \oplus (g \ominus f))\; x
      &=& f\;x \oplus (g \ominus f)\; x\; (\zero\; x)\\
      &=& f\;x \oplus (g \; (x \oplus \zero\; x) \ominus f \; x)\\
      &=& g\; (x \oplus \zero\; x) & \text{by IH at $B$}\\
      &=& g\; x & \text{by IH at $A$}
      \end{array}\]

  \end{description}
\end{proof}


\section{Metatheory}

%% \todo{$\GD_{A \to B}$ IS WRONG: it doesn't ensure that $f \oplus df$ is still monotone!}

\begin{theorem}[Legitimacy]
  Given $\J{\GP}{\GG}{e}{A}$ we have $\den{\delta e} \in \GD_{\Disc{\Psi} \x \GG
    \to A}(\den{e})$.
\end{theorem}

\begin{theorem}[Correctness]
  Given $\J{\GP}{\GG}{e}{A}$, $\psi \in \Den{\GP}$, $\gamma \in \Den{\GG}$,
  $\delta\psi \in \GD_\Psi{\psi}$, $\delta\gamma \in \GD_\GG(\gamma)$, we have
  \begin{equation*}
    \den{e}\; (\psi \oplus \delta \psi)\; (\gamma \oplus \delta\gamma)
    =
    \den{e}\; \psi\; \gamma \oplus
    \den{\delta e}\;(\psi, \gamma, \delta \psi) \; \delta\gamma
  \end{equation*}
\end{theorem}

Strategy: attack each by induction on $\J{\GP}{\GG}{e}{A}$. Try legitimacy
first.

NB. In order for that last $\oplus$ to be well-defined, we need legitimacy to
hold.


\section{Stuff to put in this document}

\begin{enumerate}
\item Correctness criterion for $\delta$ (see google doc).
\item Lemma: for decidable semilattices, $\den{e} \oplus \den{f} = \den{e \vee
  f}$.
\item Lemma justifying $\delta (\unit : A \to L) = \unit : \Disc{A} \to
  \Delta{A} \to \Delta{L}$ at functional types.
\item Definition of $\Delta_A : \Den{A} \to \ms{Poset}$.

  or $\Delta(A, a) \in \ms{Poset}$ for $a \in \Den{A}$
\item Show $\Delta_A(a)$ is an induced subposet of $\Den{A}$.
\item Define $\oplus_A : a : \Disc{\Den{A}} \to \GD_A(a) \to \Den{A}$ and show it
  is monotone in its second argument. This also involves defining \zero.
\end{enumerate}

\end{document}
