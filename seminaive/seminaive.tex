\documentclass{article}
\usepackage[a4paper,margin=0.8in]{geometry}

\usepackage{datafun}

%% Allows using >{blah} and <{blah} in array formats.
\usepackage{array}

%% for \midrule
\usepackage{booktabs}

\newcommand{\dummy}{\ms{dummy}}

\begin{document}

\section{Poset terminology}

\begin{definition}[Chain]
  In a poset $A$, a \emph{chain} is a monotone map $f : \N \to A$, which we
  interpret as an infinite nondecreasing sequence of $A$s, $f(0) \le f(1) \le
  f(2) \le ...$.
\end{definition}

\begin{definition}[Strict chain]
  A chain $f : \N \to A$ is \emph{strict} if $i < j \implies f(i) < f(j)$; in
  other words, an infinite strictly increasing sequence of $A$s, $f(0) < f(1) <
  f(2) < ...$.
\end{definition}

\begin{definition}[Stops at]
  A chain $a_0 \le a_1 \le a_2 \le ...$ \emph{stops at $i$} iff $a_i$ is the
  supremum of all $a_j$. Equivalent formulations:
  \[\begin{array}{ccccc}
    a_i = \sup_j a_j
    &\Leftrightarrow& \forall(j \ge i)\ a_j \le a_i
    &\Leftrightarrow& \forall(j \ge i)\ a_i = a_j\\
  \end{array}\]
\end{definition}

\begin{definition}[Stops]
  A chain $a$ \emph{stops} iff it contains its own supremum (iff $\exists
  i\binder a~\text{stops at}~i$).
\end{definition}

\begin{observation} Strict chains don't stop. \end{observation}

\begin{definition}
  For a chain $f$, let the sequence $f^s$ (``the strictification of $f$'') be
  $f$ with all repeated elements stripped out. If $f^s$ is infinite, it is by
  construction a strict chain.
\end{definition}

%% \begin{observation}
%%   If $f$ is a strict chain, $f^s = f$, since strict chains have no repeated
%%   elements.
%% \end{observation}

\begin{lemma}
  Given a chain $a$, $a^s$ is finite iff $a$ stops (and $a^s$ is a strict chain
  iff $a$ does not stop).
\end{lemma}
\begin{proof}
  Note that the ranges of $a$ and $a^s$ are identical by construction.

  First, suppose $a^s$ is finite. Note that the last element of $a^s$ is its
  largest, and therefore the supremum of both sequences, since they have the
  same range. Therefore $a$ contains its own supremum, and stops.

  Second, suppose $a$ stops. Thus it contains the supremum of both sequences.
  Let $i$ be the index such that $a^s_i$ is this supremum. There can be no
  elements in $a^s$ after $a^s_i$. Thus $a^s$ is finite.
\end{proof}

\begin{definition}[ACC]
  A poset satisfies the \emph{ascending chain condition (ACC)} iff all chains in
  it stop, or equivalently, if it has no strict chains.
\end{definition}

``Every chain stops'' implies no strict chains exist, since every strict chain
is a chain and strict chains do not stop. Likewise, ``no strict chains exist''
implies every chain stops, since for every non-stopping chain $f$ there is a
strict chain $f^s$.

%% \begin{theorem}[ACC $\Leftrightarrow$ no strict chains]
%%   A poset $A$ satisfies ACC iff there are no strict chains on $A$.
%% \end{theorem}
%% \begin{proof}
%%   First, we show ACC implies no strict chains. Assume $A$ satisfies ACC.
%%   Consider some strict chain $f : \N \to A$. Any strict chain is a chain.
%%   Therefore by ACC $\exists i\ \forall(j \ge i)\ f(j) \le f(i)$. Letting $j = i
%%   + 1$, we have $f(i) < f(i + 1)$ by $f$'s strictness, and $f(i) \ge f(i+1)$ by
%%   ACC. Contradiction!

%%   Second, we show no strict chains implies ACC. Assume $A$ has no strict chains.
%%   Consider some (weak) chain $f : \N \to A$. Now, let the sequence $f^s$ be $f$
%%   with repeated elements stripped out, so that $f^s$ is strictly increasing, but
%%   might no longer be an infinite sequence. Since $A$ has no strict chains, we
%%   know $f^s$ is finite. Consider the index $i$ in $f$ of the first occurrence of
%%   the last (and thus greatest) element of $f^s$. By construction we have
%%   $\forall (j \ge i)\ f(j) \le f(i)$. Thus $A$ satisfies ACC.
%% \end{proof}

\begin{definition}[Downset on an element]
  The \emph{downset on $x$} in a poset $A$, written $\downintro{x : A}$ or just
  $\downintro{x}$, is the freely generated downward-closed subset of $A$
  containing $x$, namely $\setfor{y \in A}{y \le x}$.
\end{definition}

\begin{definition}[Downset]
  A \emph{downset} on a poset $A$ is a finitely-generated downward-closed subset
  of $A$; that is to say, for some \emph{finite} subset $G \finsubseteq A$, it
  is $\bigcup_{x \in G} \downintro{x}$, or equivalently $\setfor{y \in
    A}{\exists(x \in G)\ y \le x}$.
\end{definition}

Note that this definition of \emph{downset} is in fact what others might call a
\emph{finitely generated downset}. I prefer the term \emph{downward-closed set}
for the more general concept.

We will often regard a downset $D$ of $A$ as a poset, with the same ordering
relation as $A$, restricted to elements of $D$ (the ``induced ordering'').

\todo{I probably no longer need all this theory about downset-ACC types and can
  just use elementwise-ACC types.}

\begin{definition}[Downset ACC]
  A poset $A$ is \emph{downset-ACC} iff every downset $D$ of $A$ satisfies
  ACC.
\end{definition}

\begin{lemma}[The union of ACC sets is ACC]\label{lemma:acc-union}
  Given a poset $\tuple{A,\le}$ and two subsets $B,C \subseteq A$, if
  $\tuple{B,\le}$ and $\tuple{C,\le}$ each satisfy ACC, then so does $\tuple{B
    \cup C, \le}$.
\end{lemma}
\begin{proof}
  Assume $B$ and $C$ satisfy ACC.
  %%
  It suffices to show that there are no strict chains in $B \cup C$.
  So consider some strict chain $f : \N \to B \cup C$.
  %%

  We can split $f(0) < f(1) < f(2) < ...$ into two strictly increasing sequences
  $b_0 < b_1 < b_2 < ...$ and $c_0 < c_1 < c_2 < ...$ by including in $b_i$ all
  and only those $f(j) \in B$ and likewise in $c_i$ all and only those $f(j) \in
  C$. Since $f$ is infinite, at least one of these sequence is infinite; WLOG,
  assume $b$ is. Thus $b$ is a strict chain in $B$! But by ACC there are no
  strict chains in $B$. Contradiction.
\end{proof}

\begin{theorem}[Elementwise ACC implies Downset ACC]
  A poset $A$ is downset-ACC if, for any $x : A$, $\downintro{x}$ satisfies ACC.
\end{theorem}
\begin{proof}
  The empty set clearly satisfies ACC. Given two subposets $D,E \subseteq A$
  which both satisfy ACC, their union $D \cup E$ also satisfies ACC by Lemma
  \ref{lemma:acc-union}. Every downset is the finite union of zero or more
  singly-generated downsets of the form $\downintro{x}$. So by induction, if
  every singly-generated downset $\downintro{x}$ satisfies ACC, so do all
  downsets.
\end{proof}



\section{Core Datafun}

\todo{We should carefully distinguish which properties are necessary to safely
  extend core Datafun --- and therefore, which proofs are ``open''. For example,
  all that should be necessary to add a type to Datafun and declare it decidable
  is that it should actually \emph{be} decidable. However, for \emph{decidable
    semilattice types}, we require that Lemma \ref{lemma:dl-boring} holds in
  order to extend the language with them.

  This means that when proving something about decidable types, we cannot do it
  by induction (or we violate extensibility), only by invoking the fact that
  they are decidable. But when proving something about decidable semilattice
  types, we can use Lemma \ref{lemma:dl-boring}. The proof of Lemma
  \ref{lemma:dl-boring} gets to use induction, but the hypothesis can't be
  strengthened (or we'd violate extensibility).}

\subsection{Syntax}

\[
\begin{array}{rccl}
  \textsf{types} & A,B,C
  &\bnfeq& A \to B \pipe A \x B \pipe A + B
  \pipe \Disc{A} \pipe \Seteq{A} \pipe \tbool
  \vspace{1em}\\

  %% types where the poset relationship is decidable
  \textsf{decidable types} & \eq{A}
  &\bnfeq& \eq{A} \x \eq{B} \pipe \eq{A} + \eq{B}
  \pipe \Disc{\eq{A}} \pipe \Seteq{A} \pipe \tbool
  \vspace{1em}\\

  %% finite types
  \textsf{finite types} & \fin{A}
  &\bnfeq& \fin{A} \x \fin{B} \pipe \fin{A} + \fin{B}
  \pipe \Disc{\fin{A}} \pipe \Set{\fin{A}} \pipe \tbool
  \vspace{1em}\\

  %% acc types
  \textsf{ACC types} & \acc{A}
  &\bnfeq& \acc{A} \x \acc{B} \pipe \acc{A} + \acc{B}
  \pipe \Disc{A} \pipe \Set{\fin{A}} \pipe \tbool
  \vspace{1em}\\

  %% elementwise-ACC types
  \textsf{elementwise-ACC types} & \eltacc{A}
  &\bnfeq& \eltacc{A} \x \eltacc{B} \pipe \eltacc{A} + \eltacc{B}
  \pipe \Disc{A} \pipe \Seteq{A} \pipe \tbool
  \vspace{1em}\\

  %% semilattice types
  \textsf{semilattice types} & \lat{A}
  &\bnfeq& A \to \lat{B} \pipe \lat{A} \x \lat{B} \pipe \Seteq{A} \pipe \tbool
  \vspace{1em}\\

  %% decidable semilattice types
  \textsf{decidable semilattice types} & \eqlat{A}
  &=& \eq{A} \cap \lat{A}
  \vspace{1em}\\

  %% fixpoint types
  \textsf{fixed-point types} & \fixtype{A}
  &=& \eq{A} \cap \lat{A} \cap \acc{A}
  \vspace{1em}\\

  %% TODO: note that, currently, \eq{A} \cap \eltacc{A} = \eq{A}?
  %% however, this would change if we added lexical sums.
  %% (nat <+ 1) is not elementwise-acc, for example.
  \textsf{bounded fixed-point types} & \fixletype{A}
  &=& \eq{A} \cap \lat{A} \cap \eltacc{A}
  \vspace{1em}\\

  %% expressions
  \textsf{expressions} & e,f,g
  &\bnfeq& \m{x} \pipe \d{x} \pipe \fn\bind{\m{x}} e \pipe e\; e
  \pipe \pair{e}{e} \pipe \pi_i\; e\\
  &&\pipe& \inj{i}{e} \pipe \case{e}{\m{x}}{e_1}{\m{x}}{e_2}\\
  &&\pipe& \disc{e} \pipe \letdisc{\d{x}}{e}{e} \pipe \splitsum{e}\\
  &&\pipe& \unit \pipe e \vee e \pipe \single{e} \pipe \setelim{\m{x}}{e}{e}\\
  &&\pipe& \etrue \pipe \efalse \pipe \when{e}{e} \pipe \ifthen{e}{e}{e}\\
  &&\pipe& \fix{\m{x}}{e} \pipe \fixle{\m{x}}{e}{e}
\end{array}
\]

I use blue script for monotone variables $\m{x}$, and orange bold for discrete variables $\d{x}$.

The ``typeclass'' rules (for decidable, finite, ACC, elementwise-ACC, semilattice, etc.\! types) are \emph{conservative approximations} of the corresponding semantic conditions.

``Decidable types'' are those whose partial ordering relation is practically decidable; that is, given $x, y : \eq{A}$, there is a reasonable algorithm that determines whether $x \le y$.
%%
By antisymmetry, this also makes equality $x = y$ testable at these types. Theoretically, a function type $\under{fin}{A} \to \eq{B}$ whose domain is finite and codomain is decidable is also decidable.
%%
We have omitted this, as it complicates our implementation for little practical
benefit.
%%
We have similarly omitted the cases in which function types are finite $\fin{A} \to \fin{B}$, ACC $\fin{A} \to \acc{B}$, and elementwise-ACC $\fin{A} \to \eltacc{B}$.


\subsection{Typing rules}

The typing judgment \[\J{\d{\GP}}{\m{\GG}}{e}{A}\] says that $e$ has type $A$ using variables with types given by $\d{\GP} \cup \m{\GG}$, and moreover uses the variables in $\m{\GG}$ in a monotone fashion.
%% 
Where possible without ambiguity, I omit the contexts $\dt{\GP};\mt{\GG}$ from typing rules.

\begin{mathpar}
  \infer{\J{\GP}{\GG}{\m{x}}{A}}{\mt{\m{x} \of A} \in \mt{\GG}}

  \infer{\J{\GP}{\GG}{\d{x}}{A}}{\dt{\d{x} \of A} \in \dt{\GP}}

  \infer{\fn\bind{\m{x}} e : A \to B}{\J{\GP}{\GG,\m{x} \of A}{e}{B}}

  \infer{e \; f : B}{e : A \to B & f : A}
  \\
  %% \infer{\pair{e}{f} : A \x B}{e : A & f : B}
  \infer{\pair{e_1}{e_2} : A_1 \x A_2}{e_i : A_i}

  \infer{\pi_i\; e : A_i}{e : A_1 \x A_2}

  \infer{\inj{i}{e} : A_1 + A_2}{e : A_i}

  \infer{\case{e}{\m{x}}{f_1}{\m{x}}{f_2} : B}
        {e : A_1 + A_2 & \J{\GP}{\GG, \m{x} \of A_i}{f_i}{B}}
  \\
  \infer{\J{\GP}{\GG}{\disc{e}}{\Disc{A}}}{\J{\GP}{-}{e}{A}}

  \infer{\letdisc{\d{x}}{e}{f} : B}
        { e : \Disc{A}
        & \J{\GP, \d{x}\of A}{\GG}{f}{B}}

  \infer{\splitsum{e} : \Disc{A} + \Disc{B}}
        {e : \Disc{(A + B)}}
  \\
  \infer{\unit : \lat{A}}{}

  \infer{e_1 \vee e_2 : \lat{A}}{e_i : \lat{A}}

  \infer{\J{\GP}{\GG}{\single{e}}{\Seteq{A}}}
        { \J{\GP}{-}{e}{\eq{A}} }

  %% TODO: explain that although we allow only decidable types here, we can
  %% eta-expand function types, so we can pretend we allow any semilattice type.
  \infer{\setelim{\d{x}}{e}{f} : \eqlat{B}}
        { e : \Seteq{A}
        & \J{\GP, \d{x} \of A}{\GG}{f}{\eqlat{B}}}
  \\
  \infer{\etrue : \tbool}{}

  \infer{\efalse : \tbool}{}

  \infer{\when{e}{f} : \lat{A}}{e : \tbool & f : \lat{A}}

  \infer{\ifthen{e}{f_1}{f_2} : A}{e : \Disc{\tbool} & f_i : A}
  \\
  \infer{\fix{\m{x}}{e} : \fixtype{A}}{
    \J{\GP}{\GG, \m{x}\of\fixtype{A}}{e}{\fixtype{A}}}

  \infer{\fixle{\m{x}}{e}{f} : \fixletype{A}}{
    e : \fixletype{A} &
    \J{\GP}{\GG, \m{x}\of\fixletype{A}}{f}{\fixletype{A}}}
\end{mathpar}


\section{A Theory of Changes for Core Datafun}

\subsection{Change types}

For each type $A$ we define a change type $\Ch A$.

\[\begin{array}{rcl>{\quad\quad}rcl}
  \Ch(A \to B) &=& \Disc{A} \to \Ch A \to \Ch B\\
  \Ch(A \x B) &=& \Ch A \x \Ch B\\
  \Ch(A + B) &=& \Ch A + \Ch B\\
  \Ch \Disc{A} &=& \Disc{\Ch A}\\
  \Ch\thinspace \Seteq{A} &=& \Seteq{A}\\
  \Ch\thinspace \tbool &=& \tbool
\end{array}\]

We also define associated operators $\oplus : A \to \Ch A \to A$, $\ominus : A
\to A \to \Ch A$ and $\zero : A \to \Ch A$. Note, however, the
definitions of these operators \emph{are not well-typed Datafun terms}. \todo{I
  do not believe there exists a way to assign them tones that is compatible with
  Datafun's type system; every way I've tried fails. But I have not proved
  this.}

As for the semantic tonal behavior of these operators, I believe I know this
much:
\begin{itemize}
\item $x \oplus dx$ is monotone in $dx$.
\item $x \ominus y$ is monotone in $x$ and antitone in $y$.
\item $\zero$ is discrete; at function type, it finds the derivative of its
  argument, and a function that is larger pointwise does not necessarily have a
  derivative that is larger pointwise.
\end{itemize}

But is $\oplus$ monotone in its first argument? I'm not sure. It seems wrong to
contemplate changing its first argument without also changing its second ---
really it should have a dependent type.

\begin{center}
\[
\scalebox{0.85}{\(
\arraycolsep=1.5em
\begin{array}{cccc}
  \textbf{Type}
  & {\textbf{Definition of}~\oplus}
  & {\textbf{Definition of}~\ominus}
  & {\textbf{Definition of}~\zero}
  \\ \midrule
  A \to B
  & (f \oplus df)\; x = f\; x \oplus df\; x\; (\zero\; x)
  & (f \ominus g)\; x \;dx = f\; (x \oplus dx) \ominus g \; x
  & \zero\; f\; x\; dx = f\; (x \oplus dx) \ominus f\; x
  \\
  A \x B
  & \pair{x}{y} \oplus \pair{dx}{dy} = \pair{x \oplus dx}{y \oplus dy}
  & \pair{a}{x} \ominus \pair{b}{y} = \pair{a \ominus b}{x \ominus y}
  & \zero \; \pair{x}{y} = \pair{\zero\; x}{\zero\; y}
  \\
  A + B
  & \inj{i}{x} \oplus \inj{i}{dx} = \inj{i}{(x \oplus dx)}
  & \inj{i}{x} \ominus \inj{i}{y} = \inj{i}{x \ominus y}
  & \zero\; (\inj{i}{x}) = \inj{i}{(\zero\;x)}
  \\
  \Disc{A}
  & \disc{x} \oplus \disc{dx} = \disc{x \oplus dx}
  & \disc{x} \ominus \disc{y} = \disc{x \ominus y}
  & \zero\; \disc{x} = \disc{\zero\; x}
  \\
  \Seteq{A}
  & x \oplus y = x \vee y
  & x \ominus y = x
  & \zero\; x = \unit
  \\
  \tbool
  & x \oplus y = x \vee y
  & x \ominus y = x
  & \zero\; x = \unit
\end{array}
\)}
\]
\end{center}

These should satisfy the following laws:
\begin{eqnarray}
  x \le y \quad\implies\quad
  y &=& x \oplus (y \ominus x)\\
  x &=& x \oplus \zero\; x
\end{eqnarray}

\todo{TODO: Prove these laws hold.}

\todo{TODO: Note about ``erasure''/invalid changes. Moreover, at $\Disc{A}$
  type, only valid changes are zero changes.}

\todo{TODO: Note about efficiency of computing $\oplus$, $\ominus$, $\zero$,
  and which ones we actually need to compute in the implementation. Define
  efficiently computable $(- \ominus \unit)$ operator for decidable types, and
  point out that $\zero$ is efficiently computable for decidable types.}

%% Zero on decidable types.
%% Zero on decidable types:
%% \[\arraycolsep=1.5em
%% \begin{array}{c|c}
%%   \eq{A} \x \eq{B}
%%   & \zero\; (x,y) = (\zero\; x, \zero\; y)
%%   \\
%%   \eq{A} + \eq{B}
%%   & \zero\; (\inj{i}{x}) = \inj{i}(\zero\; x)\\
%%   \Disc{\eq{A}}
%%   & \zero\;(\disc{x}) = \disc{(\zero\; x)}\\
%%   \Down{\eq{A}} & \zero\;x = \unit\\
%%   \tbool & \zero\; x = \unit
%% \end{array}
%% \]


%% Some lemmas.
\begin{lemma}[Changes on a semilattice form a semilattice]
  $\Ch \lat{A}$ is a semilattice type.

  \todo{TODO: do we actually need/use this lemma?}
\end{lemma}
\begin{proof}
  By induction on the cases:
  \begin{eqnarray*}
    \Ch(A \to \lat{B}) &=& \Disc{A} \to \Ch A \to \Ch \lat{B}\\
    \Ch(\lat{A} \x \lat{B}) &=& \Ch \lat{A} \x \Ch \lat{B}\\
    \Ch\thinspace \Seteq{A} &=& \Seteq{A}\\
    \Ch\thinspace 2 &=& 2
  \end{eqnarray*}
\end{proof}

\begin{lemma}[Changes on decidable semilattices are boring]\label{lemma:dl-boring}
  For any decidable semilattice type $\eqlat{A}$, $\Ch \eqlat{A} = \eqlat{A}$,
  and moreover the following laws hold:
  \begin{eqnarray*}
    x \oplus y &=& x \vee y\\
    x \ominus y &=& x\\
    \zero\; x &=& \unit
  \end{eqnarray*}
\end{lemma}
\begin{proof}
  By induction on the cases:
  \[\begin{array}{rcl}
    \Ch(\eqlat{A} \x \eqlat{B}) &=& \Ch \eqlat{A} \x \Ch \eqlat{B}\\
    \Ch\thinspace \Seteq{A} &=& \Seteq{A}\\
    \Ch\thinspace \tbool &=& \tbool
  \end{array}\]

  And, for the operations:
  \[\arraycolsep=0.75em
  \begin{array}{c|ccc}
    \eqlat{A} \x \eqlat{B}
    & (x,y) \oplus (dx,dy) = (x \oplus dx, y \oplus dy)
    & (a,x) \ominus (b,y) = (a \ominus b, x \ominus y)
    & \zero\; (x,y) = (\zero\; x, \zero\; y)\\
    \Down{\eq{A}}
    & x \oplus y = x \vee y
    & x \ominus y = x
    & \zero\;x = \unit\\
    \tbool
    & x \oplus y = x \vee y
    & x \ominus y = x
    & \zero\;x = \unit\\
  \end{array}
  \]
\end{proof}


\subsection{Derivatives}

We wish to define an operator $\delta$ on typing derivations (or if possible, on
well-typed terms) such that the following holds:
\[\infer{\J{\GP,\GG,\Ch\GP}{\Ch\GG}{\delta e}{\Ch A}}
        {\J{\GP}{\GG}{e}{A}}
\]

As a matter of convention, prefixing a variable with $d$ refers to the
corresponding variable of its change type. That is, if $x \of A \in \GP \cup
\GG$, then $dx \of \Ch A \in \Ch\GP \cup \Ch\GG$. We also make implicit use of
weakening and monotone-to-discrete weakening (that is, if
$\J{\GP}{\GG_1,\GG_2}{e}{A}$, then $\J{\GP,\GG_1}{\GG_2}{e}{A}$).

\newcommand{\preserve}[1]{{\color{ForestGreen}{\disc{#1}}}}

\todo{\indent Furthermore, if $e : A$ originally, then in the the
  $\delta$-context, $\preserve{e} : \Disc{A}$ for free, since all the variables
  $e$ uses are now discrete. Can/do we take advantage of this?}
     {\color{ForestGreen} Yes we do! We mark such uses with green to make them
       stand out.}

\[
\begin{array}{lcll}
  \delta \m{x} &=& \m{dx}\\
  \delta \d{x} &=& \d{dx}\\
  \delta(\fn\bind{\m{x}} e) &=&
  \fn\bind{\disc{\d{x}} \, \m{dx}} \delta e\\
  \delta(e\;f) &=& \delta e \; \preserve{f} \; \delta f\\
  \delta \pair{e}{f} &=& \pair{\delta{e}}{\delta{f}}\\
  \delta(\pi_i\; e) &=& \pi_i\; \delta{e}\\
  \delta(\inj{i}{e}) &=& \inj{i}{\delta{e}}\\

  \delta(\case{e}{\m x}{f}{\m y}{g})
  &=& \mathbf{case} \; \pair{\splitsum{\preserve{e}}}{\delta e} ~\mathbf{of}\\
   && \quad \pair{\inj{1}{\disc{\d{x}}}}{\inj{1}{\m{dx}}} \cto \delta f\\
   && \quad \pair{\inj{2}{\disc{\d{y}}}}{\inj{2}{\m{dy}}} \cto \delta g\\
   && \quad \pair{\inj{1}{\disc{\d{x}}}}{\inj{2}{\m{\pwild}}} \cto
      \letv{\m{dx}}{\dummy\; \d{x}} \delta f\\
   && \quad \pair{\inj{2}{\disc{\d{y}}}}{\inj{1}{\m{\pwild}}} \cto
      \letv{\m{dy}}{\dummy\; \d{y}} \delta g\\

  \delta\disc{e} &=& \disc{\delta e}\\
  \delta(\letdisc{\d{x}}{e} f) &=&
  %% TODO: Wait, is this right? Check with Agda code.
    \letdisc{\d{x}}{e} \letdisc{\d{dx}}{\delta e} \delta f\\

  \delta(\splitsum{e}) &=&
  %% want type: Δ□A + Δ□B = □ΔA + □ΔB
  %% e : □(A + B)
  %% δe : □(ΔA + ΔB)
  %% splitsum δe : □ΔA + □ΔB
  \splitsum{\delta e}\\
  \delta \unit &=& \unit\\
  \delta(e \vee f) &=& \delta e \vee \delta f
  \qquad \text{(this is the critical over-approximation)}\\
  \delta(\single{e}) &=& \unit\\
  \delta(\setelim{\d{x}}{e}{f}) &=& \text{\todo{see below}}\\
  \delta(\etrue) &=& \efalse\\
  \delta(\efalse) &=& \efalse\\
  \delta(\when{e}{f})
  &=& \ifthen{\preserve{e}}{\delta f}{
    \when{\delta e}{(f \oplus \delta f) \ominus \unit}}
  \qquad \text{\color{red} see below}\\
  \delta(\ifthen{e}{f}{g}) &=& \ifthen{e}{\delta f}{\delta g}\\
  \delta(\fix{\m{x}}{e}) &=&
  \letdisc{\d{x}}
          {\disc{\fix{\m{x}} {\color{ForestGreen}e}}}
          {\fix{\m{dx}} \delta e}\\
  \delta(\fixle{\m{x}}{e}{f}) &=& \text{\TODO}
\end{array}
\]

At decidable types, $\delta(\setelim{\d{x}}{e}{f})$ has the following definition:

\[\begin{array}{rcl}
  \delta(\setelim{\d{x}}{e}{f})
  &=& \phantom{\vee~} (\setelim{\d{x}}{e}{\letv{\m{dx}}{\zero\; \d{x}} \delta f})
  \\ && \vee~ (\setelim{\d{x}}{\delta e}{\letv{\m{dx}}{\zero\; \d{x}}
    (f \oplus \delta f) \ominus \unit})
\end{array}\]

\todo{TODO: Explain/show that $\oplus$, $(- \ominus \unit)$, and \zero{} are
  definable, typeable, and efficiently computable at these types!}

Translation of $\setelim{\d{x}}{e}{f}$ at \emph{non-decidable types}, however,
is type-directed:

\[\begin{array}{lcll}
  \delta(\setelim{\d{x}}{e}{f} : A \to \lat{B})
  &=& \delta(\fn\bind{\m y} \setelim{\d{x}}{e}{f\; \m y})\\
  \delta(\setelim{\d{x}}{e}{f} : \lat{A} \x \lat{B})
  &=& \pair{\delta(\setelim{\d{x}}{e}{\pi_1\; f})}
  {\delta(\setelim{\d{x}}{e}{\pi_2\; f})}
\end{array}\]

\emph{Hypothesis}: For $a : \lat{A}$ and $da : \Ch\lat{A}$ a valid change to
$a$:
\begin{equation*}
  (a \oplus da) \ominus \unit = (a \ominus \unit)
  \vee da
\end{equation*}

\emph{Observation}: Consider $(\when{e}{f})$ for $f : A \to \lat{B}$. We can
rewrite this as $(\fn\bind{x} \when{e}{f\; x})$. This turns a \ms{when} at type
$A \to \lat{B}$ into one at type $\lat{B}$. By extending this we can rewrite
away all uses of \ms{when} at functional types, in the same manner as we can
rewrite away uses of $\bigvee$ at functional type.

\todo{\par TODO: Proofs which Neel \& I worked out last time.}


\subsubsection{Dummy values}

The derivative of $\ms{case}$ has branches we know semantically cannot occur;
but to appease the type system, we need to put an expression in those branches
of the appropriate type. Instead of introducing an \ms{abort} construct, which
would complicate our semantics, we generate an expression of the appropriate
type using a type-indexed dummy-value function $\dummy{} : A \to \Ch{A}$.

\todo{TODO: actually, I think we can give \dummy{} the type $A \to
  \Disc{\Ch{A}}$. Should we?}

\[\begin{array}{lcl}
\dummy\; (x : \tbool) &=& \efalse\\
\dummy\; (x : \Seteq{A}) &=& \unit\\
\dummy\; \pair{x}{y} &=& \pair{\dummy\;x}{\dummy\;y}\\
\dummy\; (\inj{i}{x}) &=& \inj{i}{(\dummy\;x)}\\
\dummy\; \disc{\d{x}} &=& \disc{\dummy\; \d{x}}\\
\dummy\; (f : A \to B) &=&
  \fn \disc{\d{x}} \, \m{dx} \binder\, \dummy\;(f\;\d{x})
\end{array}\]

This is a hack to simplify our metatheory. A real implementation would not do
this.

\todo{NB. To add a type to Datafun, we must extend \dummy{} appropriately.}


\subsubsection{Justifying derivatives of fixed points}

Our rule for the derivative of a fixed point is:
\begin{eqnarray*}
  \delta(\fix{\m{x}} e)
  &=& \letdisc{\d{x}}{\disc{\fix{\m{x}} e}} \fix{\m{dx}} \delta e\\
  &=& \fix{\m{dx}}
      (\fn \disc{\d{x}}\, \m{dx}\binder\, \delta e)
      \; \disc{\fix{\m{x}} e}
      \; \m{dx}\\
  &=& \fix{\m{dx}} \delta(\fn\bind{\m{x}} e)
      \; \disc{\fix{\m{x}} e}
      \; \m{dx}
\end{eqnarray*}

Why is this correct? First, let's rephrase this in terms of an operator
$\ms{fix} : (\fixtype{A} \to \fixtype{A}) \to \fixtype{A}$:
\begin{equation}
  \delta(\ms{fix}\; f) = \ms{fix}\; (\delta f \;\disc{\ms{fix}\; f})
\end{equation}

This is such a beautiful equation it can't be wrong. How did we arrive at this
equation? Well,
\[
\begin{array}{rcl>{\hspace{1em}}l}
  \delta(\ms{fix}\; f)
  &=& \delta(f \;(\ms{fix}\;f))
  & \text{because}~\ms{fix}\; f = f\;(\ms{fix}\;f)\\
  &=& \delta f \;\disc{\ms{fix}\; f} \; \delta(\ms{fix}\; f)
  & \text{rule for}~\delta(e_1\;e_2)
\end{array}
\]

We've now found a recursive equation that describes
${\color{Cyan}\delta(\ms{fix}\;f)}$ in terms of itself:
\begin{equation}\label{eqn:delta-fix}
  {\color{Cyan} \delta(\ms{fix}\;f)}
  = \delta f \;\disc{\ms{fix}\; f} \; {\color{Cyan}\delta(\ms{fix}\;f)}
\end{equation}

Let's apply \ms{fix} to solve the equation!
\begin{equation*}
  \delta(\ms{fix}\; f)
  =
  \ms{fix}\,(\fn\bind{\m{\color{Cyan} dx}}
  \delta f \;\disc{\ms{fix}\;f} \;{\m{\color{Cyan} dx}})
\end{equation*}

However, this is not a proof of correctness. We merely established that it
was \emph{true} that equation \ref{eqn:delta-fix} holds, not that it suffices as
a \emph{definition} of $\delta(\ms{fix}\;f)$. The correctness criterion for
$\delta(\ms{fix}\; f)$ is:

\begin{equation}
  \ms{fix}\;f \oplus \delta(\ms{fix}\;f)
  = (\ms{fix}\;f)\sub{\gamma \oplus \delta\gamma/\gamma}
\end{equation}

That is, a $\ms{fix}$ expression plus its derivative equals the original
expression computed with updated free variables. We give a proof of this for our
definition of $\delta(\ms{fix}\;f)$ in \url{fixderiv.pdf}, which is also
available \href{http://www.rntz.net/files/fixderiv.pdf}{online}. This proof is
quite generic, and not specific to Datafun; as such, it assumes a few lemmas,
which we prove here:

\par \todo{TODO: insert proofs of the lemmas from \texttt{fixderiv} here}

%% \begin{lemma}
%%   $x \le x \oplus dx$
%%   \label{lemma:oplus-increasing}
%% \end{lemma}
%% \begin{proof}
%%   \todo{TODO.}
%% \end{proof}

%% \begin{lemma} For $f : A \to B$, $x : A$, $df : \Ch (A \to B)$, and $x :
%%   \Ch A$, where $df$ and $dx$ are valid changes to $f$,$x$ respectively (see
%%   section on ``Dependent change types'', below), we have:
%%   \[(f \oplus df) \; (x \oplus dx) = f\;x \oplus df\;x\;dx\]
%% \end{lemma}
%% \begin{proof}
%%   \todo{TODO. See figure 4, page 5, in Cai et al.}
%% \end{proof}

%% I don't know whether we need this theorem.

%% \begin{theorem}[Soundness of ordering on change types]
%%   For any $dx, dx' : \Ch A$, if $dx \le dx'$, then for any $x : A$, we have
%%   $x \oplus dx \le x \oplus dx'$.
%% \end{theorem}
%% \begin{proof}
%%   \todo{TODO. This seems like it should be true. Note that we don't \emph{need}
%%     this to be true for all types, just for fixed-point types $\fixtype{A}$, but
%%     it would be surprising if it weren't true generally.}
%% \end{proof}


\section{Fixed points}

\[\begin{array}{l}
  \textsf{fast-fix} ~:~
  (\Disc{\fixtype{A}} \to \Ch\fixtype{A} \to \Ch\fixtype{A})
  \to \fixtype{A} \to \Ch\fixtype{A} \to \fixtype{A}\\
  \textsf{fast-fix}\; \mi{df}\; \mi{current}\; \mi{change} =\\
  \quad \textbf{let}~ {\mi{next} = \mi{current} \oplus \mi{change}}
  ~\textbf{in}\\
  \quad \textbf{if}~ \mi{next} \le \mi{current}
  ~\textbf{then}~ \mi{current}\\
  \quad \textbf{else}~ \textsf{fast-fix}\; \mi{df}\; \mi{next}
  \;(\mi{df}\; \mi{current}\; \mi{change})\\
  \\
  \textsf{fast-fix}
  \in ((x : \Disc{L}) \to \Delta(L, x) \to \Delta(L, x)) \to L
  \\
  \textsf{fast-fix} \; df =\\
  \quad\textbf{let}~ \textsf{loop} \in (x : L) \to \Delta(L, x) \to L\\
  \quad\phantom{\textbf{let}~} \textsf{loop} \;x \;dx =\\
  \quad\phantom{\textbf{let}~}\quad
  \textbf{let}~ x' = x \oplus dx ~\textbf{in}\\
  \quad\phantom{\textbf{let}~}\quad
  \textbf{if}~ x' \le x ~\textbf{then}~ x\\
  \quad\phantom{\textbf{let}~}\quad
  \textbf{else}~\textsf{loop} \;x' \;(df \; x \; dx)\\
  \quad\textbf{in}~ \textsf{loop} \; \unit \; (f \; \unit \ominus \unit)
\end{array}\]


\section{Dependent change types}

We will define the following type-indexed sets and operators:

\[\begin{array}{ccccl}
  \Changes{A}{a} &\subseteq& |\Den{\Ch{A}}|
  &\text{for}& a \in \Den{A}
  \\
  a \oplus_A da &\in& \Den{A}
  &\text{for}& a \in \Den{A} ~\text{and}~ da \in \Changes{A}{a}
  \\
  b \ominus_A a &\in& \Changes{A}{a}
  &\text{for}& a, b \in \Den{A} ~\text{and}~ a \le b
  \\
  \zero_A\; a &\in& \Changes{A}{a}
  &\text{for}& a \in \Den{A}
\end{array}\]

\zero{} is simply syntax sugar; $\zero_A\; x = x \ominus_A x$. The other three
are defined mutually, by induction on types. First we give the rules for
$\Changes{A}{a}$:

\[
\def\arraystretch{1.2}
\begin{array}{lcl}
  \Changes{\tbool}{\pwild} &=& \Den{\tbool}
  \\
  \Changes{\Down{A}}{\pwild} &=& \Den{\Down{A}}
  \\
  \Changes{A_1 + A_2}{\inj{i}{x}}
  &=& \setfor{\inj{i}{dx}}{dx \in \Changes{A_i}{dx}}
  %% \\
  %% \inj{i}{dx} \in \Changes{A_1 + A_2}{\inj{i}{x}}
  %% &\iff& dx \in \Changes{A_i}{x}
  \\
  \Changes{A \x B}{\pair{a}{b}}
  &=& \Changes{A}{a} \x \Changes{B}{b}
  \\
  \Changes{\Disc{A}}{a}
  &=& \setfor{dx \in \Changes{A}{a}}{x \oplus_A dx = x}
  \\
  df \in \Changes{A \to B}{f}
  &\Leftrightarrow&
  \forall({a,b \in \Den{A}},\, da \in \Changes{A}{a},\, db \in \Changes{A}{b})\\
  &&\phantom{{}\wedge{}}
  df\; a\; da \in \Changes{B}{f\; a}
  \wedge df\;b\;db \in \Changes{B}{f\; b}
  %% \\
  %% &&{}\wedge (a \mapsto f\; a \oplus_B df\; a \; (\zero_A\; a))
  %% ~\text{is monotone}
  \\
  &&{}\wedge (a \oplus da \le b \oplus db \implies
  f\;a \oplus df\;a\;da \le f\;b \oplus df\;b\;db)
\end{array}
\]

The condition defining $df \in \Changes{A \to B}{f}$ can be phrased as requiring
that the map $(a, da) \mapsto (f\;a, df\;a\;da)$ is monotone when we order its
domain and codomain by $(a,da) \le (b,db) \iff a \oplus da \le b \oplus db$.
\todo{FIXME: see figure 4, page 5 in Cai et al. They have a different
  condition/semantics for $\Delta(A \to B)$, namely: $df \in \Changes{A \to
    B}{f}$ iff $(f \oplus df)\;(a \oplus da) = f\;a\oplus df\;a\;da$. Can ours
  prove theirs?}

And the operators:
\begin{center}
  \scalebox{1}{\(
  \begin{array}{cccc}
    \textbf{Type} & \oplus & \ominus %% & \zero
    \\ \midrule
    \tbool
    & a \oplus da = a \vee da
    & b \ominus a = b
    %% & \zero\; a = \ms{false}
    \\
    \Down{A}
    & a \oplus da = a \cup da
    & b \ominus a = b
    %% & \zero\; a = \emptyset
    \\
    A + B
    & \inj{i}{a} \oplus \inj{i}{da} = \inj{i}{a \oplus da}
    & \inj{i}{b} \ominus \inj{i}{a} = \inj{i}{b \ominus a}
    %% & \zero\; (\inj{i}{a}) = \inj{i}{\zero\; a}
    \\
    A \x B
    & \pair{a}{b} \oplus \pair{da}{db} = \pair{a \oplus da}{b \oplus db}
    & \pair{b}{y} \ominus \pair{a}{x} = \pair{b \ominus a}{y \ominus x}
    %% & \zero\;\pair{a}{b} = \pair{\zero\; a}{\zero\; b}
    \\
    \Disc{A}
    & a \oplus da = a
    & b \ominus_{\Disc{A}} a = \zero_{A}\; a
    %% & \zero_{\Disc{A}}\; a = \zero_{A}\; a
    \\
    A \to B
    & (f \oplus df)\; x = f\; x \oplus df\; x \; (\zero\; x)
    & (g \ominus f)\; x\; dx = g\; (x \oplus dx) \ominus f\; x
    %% & (\zero\; f)\; x\; dx = f\; (x \oplus dx) \ominus f\; x
  \end{array}
  \)}
\end{center}

Although we define $\Changes{A}{a}$ as a subset of the elements $\Den{\Ch{A}}$,
we consider it to be a poset with the induced ordering.

We will show the following:

\begin{enumerate}
\item If $a \le b$ then $a \oplus_A (b \ominus_A a) = b$. From this it
  follows that $a \oplus_A \zero_A\; a = a$.

\item $a \oplus_A da$ is monotone in $da$. That is: for any $a \in \Den{A}$ and
  $da, db \in \Changes{A}{a}$, if $da \le db$ in $\Den{\Ch{A}}$, then $a
  \oplus_A da \le a \oplus_A db$ in $\Den{A}$.

\item \todo{(it should be true, but do we need to show this?)} $b \ominus_A a$ is
  monotone in $b$.
\end{enumerate}

%% NB. One might think we could also say something like: ``$\zero_A\; a$ is the
%% least element of $\Changes{A}{a}$''. This might be true for $\zero$ as defined
%% (although I'm not sure it is), but it is not true of zero changes in general:
%% $\{5\}$ is a zero-change on $\{5\}$, but not the least element of
%% $\Changes{\Set{{\N}}}{\{5\}}$; the empty set (also a zero-change) is smaller.

\begin{lemma}
  If $a \le b$ then $a \oplus_A (b \ominus_A a) = b$.
\end{lemma}

\begin{proof}
  By induction on $A$:
  \begin{description}
    \item[Case $\tbool$]
      \begin{equation*}
      a \oplus_\tbool (b \ominus_\tbool a) = a \vee b = b
      \end{equation*}
      Where $a \vee b = b$ follows from $a \le b$.

    \item[Case $\Down{A}$]
      \begin{equation*}
        a \oplus_{\Down{A}} (b \ominus_{\Down{A}} a)
        = a \cup b
        = b
      \end{equation*}
      Where $a \cup b = b$ follows from $a \le b$, i.e. $a \subseteq b$.

    \item[Case $A_1 + A_2$]
      \begin{equation*}
        \inj{i}{a} \oplus (\inj{i}{b} \ominus \inj{i}{a})
        = \inj{i}{(a \oplus_{A_i} (b \ominus_{A_i} a))}
        = \inj{i}{b}  \quad\text{(by IH)}
      \end{equation*}

      We know the subscript $i$ is identical for $\inj{i}{a}$ and $\inj{i}{b}$
      because $\inj{i}{a} \le \inj{j}{b} \implies i = j$.

    \item[Case $A \x B$]
      \begin{equation*}
        \pair{a}{x} \oplus (\pair{b}{y} \ominus \pair{a}{x})
        = \pair{a \oplus (b \ominus a)}{x \oplus (y \ominus x)}
        = \pair{b}{y} \quad\text{(by IH)}
      \end{equation*}

    \item[Case $\Disc{A}$]
      \begin{equation*}
        a \oplus (b \ominus a) = a = b
      \end{equation*}
      Where $a = b$ follows from $a \le b$ and discreteness.


    \item[Case $A \to B$]
      \[\begin{array}{rcll}
      (f \oplus (g \ominus f))\; x
      &=& f\;x \oplus (g \ominus f)\; x\; (\zero\; x)\\
      &=& f\;x \oplus (g \; (x \oplus \zero\; x) \ominus f \; x)\\
      &=& g\; (x \oplus \zero\; x) & \text{by IH at $B$}\\
      &=& g\; x & \text{by IH at $A$}
      \end{array}\]

  \end{description}
\end{proof}


\section{Metatheory}

%% \todo{$\GD_{A \to B}$ IS WRONG: it doesn't ensure that $f \oplus df$ is still monotone!}

\begin{theorem}[Legitimacy]
  Given $\J{\GP}{\GG}{e}{A}$ we have $\den{\delta e} \in \GD_{\Disc{\Psi} \x \GG
    \to A}(\den{e})$.
\end{theorem}

\begin{theorem}[Correctness]
  Given $\J{\GP}{\GG}{e}{A}$, $\psi \in \Den{\GP}$, $\gamma \in \Den{\GG}$,
  $\delta\psi \in \GD_\Psi{\psi}$, $\delta\gamma \in \GD_\GG(\gamma)$, we have
  \begin{equation*}
    \den{e}\; (\psi \oplus \delta \psi)\; (\gamma \oplus \delta\gamma)
    =
    \den{e}\; \psi\; \gamma \oplus
    \den{\delta e}\;(\psi, \gamma, \delta \psi) \; \delta\gamma
  \end{equation*}
\end{theorem}

Strategy: attack each by induction on $\J{\GP}{\GG}{e}{A}$. Try legitimacy
first.

NB. In order for that last $\oplus$ to be well-defined, we need legitimacy to
hold.


\section{Stuff to put in this document}

\begin{enumerate}
\item Correctness criterion for $\delta$ (see google doc).
\item Lemma: for decidable semilattices, $\den{e} \oplus \den{f} = \den{e \vee
  f}$.
\item Lemma justifying $\delta (\unit : A \to L) = \unit : \Disc{A} \to
  \Delta{A} \to \Delta{L}$ at functional types.
\item Definition of $\Delta_A : \Den{A} \to \ms{Poset}$.

  or $\Delta(A, a) \in \ms{Poset}$ for $a \in \Den{A}$
\item Show $\Delta_A(a)$ is an induced subposet of $\Den{A}$.
\item Define $\oplus_A : a : \Disc{\Den{A}} \to \GD_A(a) \to \Den{A}$ and show it
  is monotone in its second argument. This also involves defining \zero.
\end{enumerate}

\end{document}
