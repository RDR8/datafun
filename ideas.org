* embedding into Haskell or OCaml
tagless-final style: http://okmij.org/ftp/meta-programming/#QUEL
http://okmij.org/ftp/meta-programming/quel.pdf

quoted DSLs?

* for-syntax for fixpoints

    for (fix s) blah blah blah
==> fix s is blah blah blah

* parallel choice in iteration and pattern matching

Suppose I want to define

    fun dom s = {x | (x,_) in s} âˆª {x | (_,x) in s}

We have or-patterns, so why can't I do:

    fun dom s = {x | (x,_)|(_,x) in s}

The syntax is kind of awkward (the "|" character is overloaded), but the meaning
is obvious. Problem is, it doesn't work. Only the *first* pattern to match
counts (in this case, (x,_), since it's an irrefutable pattern). Possible
solution: interpret patterns differently between "case" and looping constructs;
"case" chooses the first pattern match (prioritized choice), while looping does
*all* matches (parallel choice).

Alternatively, we could add a "parallel choice" construct over iteration loops,
written "or":

    fun dom s = {x | (x,_) in s or (_,x) in s}

Again, there'd be funny syntax issues if you wanted to mix parallel (union)
"or" loops and nested (cross product) "," loops. But the idea is sound.

* implementation via dataflow / propagators

There is a natural interpretation of fixed point as creating a dataflow graph
and then running it until quiescence (until fixed point is reached). This might
also account for various forms of "chaotic iteration" optimization! And also for
"iterative join" algorithms. (see also: "on-line monotone computation", further
down)

eg. (fix x is (e1, e2)) creates two dataflow nodes, one for e1, one for e2,
which get to refer to one another!

Or, (fix x = tabulate keys func) creates one dataflow node per key in `keys'.

where tabulate : {K} -> (K -> V) -> {K: V}

* deletion via added-removed sets?
many logical algorithms use deletion for efficiency. as long as a deleted fact
can never get re-added, this is still monotone in a sense! and this sense of
monotonicity is captured by added-removed sets!

* thoughts on polymorphism and type inference

currently the implementation has subtyping, but the only non-trivial subtypings
are (a ~> b) <: (a -> b) and width subtyping of sum types.

however, we have two forms of type quantification:
- quantification over all types
- qunatification over lattice types

using Hindley-Milner unmodified probably won't work, because how can we
determine whether a function is intended to be ordinary or monotone?

also, have to incorporate typeclass-like constraint for quantification over
lattice types.

* Future work: generalize to {some,many,all} Eilenberg-Moore categories?
* Future work: exploring lists, bags, and sets
counting things, for example, is naturally a commutative-monoid-style
computation.

* Future work: a type system for LVars?
* Future work: on-line monotone computation

Matthew Maurer is working on a datalog-like logic language for binary analysis
(https://github.com/maurer/holmes/blob/master/formal/holmes.tex) which has the
property that external predicates (representing individual analyses) can have
new facts added at any time! This requires monotonicity in aggregation
operators.

We already have monotonicity! Can we efficiently implement *on-line*
computation? That is to say, for a function (f : A ~> B) in our language, is
there an efficient way to evaluate it over *monotonically increasing* inputs?

Could use SAC (self-adjusting computation), but that's more general (works for
*arbitrarily-changing* inputs). (A monotonic function can of course involve
computing things in the non-monotonic fragment, but I *think* we're guaranteed
those won't change when we change the monotone input?)
