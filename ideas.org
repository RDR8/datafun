* implementation via dataflow / propagators

There is a natural interpretation of fixed point as creating a dataflow graph
and then running it until quiescence (until fixed point is reached). This might
also account for various forms of "chaotic iteration" optimization! And also for
"iterative join" algorithms. (see also: "on-line monotone computation", further
down)

eg. (fix x is (e1, e2)) creates two dataflow nodes, one for e1, one for e2,
which get to refer to one another!

Or, (fix x = tabulate keys func) creates one dataflow node per key in `keys'.

where tabulate : {K} -> (K -> V) -> {K: V}

* deletion via added-removed sets?
many logical algorithms use deletion for efficiency. as long as a deleted fact
can never get re-added, this is still monotone in a sense! and this sense of
monotonicity is captured by added-removed sets!

* thoughts on polymorphism and type inference

currently the implementation has subtyping, but the only non-trivial subtypings
are (a ~> b) <: (a -> b) and width subtyping of sum types.

however, we have two forms of type quantification:
- quantification over all types
- qunatification over lattice types

using Hindley-Milner unmodified probably won't work, because how can we
determine whether a function is intended to be ordinary or monotone?

also, have to incorporate typeclass-like constraint for quantification over
lattice types.

* Future work: generalize to {some,many,all} Eilenberg-Moore categories?
* Future work: exploring lists, bags, and sets
counting things, for example, is naturally a commutative-monoid-style
computation.

* Future work: a type system for LVars?
* Future work: on-line monotone computation

Matthew Maurer is working on a datalog-like logic language for binary analysis
(https://github.com/maurer/holmes/blob/master/formal/holmes.tex) which has the
property that external predicates (representing individual analyses) can have
new facts added at any time! This requires monotonicity in aggregation
operators.

We already have monotonicity! Can we efficiently implement *on-line*
computation? That is to say, for a function (f : A ~> B) in our language, is
there an efficient way to evaluate it over *monotonically increasing* inputs?

Could use SAC (self-adjusting computation), but that's more general (works for
*arbitrarily-changing* inputs). (A monotonic function can of course involve
computing things in the non-monotonic fragment, but I *think* we're guaranteed
those won't change when we change the monotone input?)
